{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "045fd35b-9a6e-4722-b597-b5392c0ccd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tempfile\n",
    "import os\n",
    "import pyreadstat\n",
    "\n",
    "#------------------------------------------------------\n",
    "# 1. Loader that downloads any NHANES .xpt file safely\n",
    "#------------------------------------------------------\n",
    "def load_nhanes_xpt(file, year=\"2015\"):\n",
    "    url = f\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/{year}/DataFiles/{file}\"\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/120.0 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "    r = requests.get(url, headers=headers)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    if b\"<html\" in r.content[:200].lower():\n",
    "        preview = r.content[:500].decode(errors=\"ignore\")\n",
    "        raise ValueError(f\"HTML returned instead of XPT:\\n{url}\\n\\nPreview:\\n{preview}\")\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".xpt\", delete=False) as tmp:\n",
    "        tmp.write(r.content)\n",
    "        tmp_path = tmp.name\n",
    "\n",
    "    try:\n",
    "        df, meta = pyreadstat.read_xport(tmp_path)\n",
    "    finally:\n",
    "        os.remove(tmp_path)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "518b32c3-0d24-4782-8651-6d6cf236c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhanes_files = {\n",
    "    \"DEMO\":      \"DEMO_I.xpt\",\n",
    "    \"HDL\":       \"HDL_I.xpt\",\n",
    "    \"TCHOL\":     \"TCHOL_I.xpt\",\n",
    "    \"TRIGLY\":    \"TRIGLY_I.xpt\",\n",
    "    \"GLU\":       \"GLU_I.xpt\",\n",
    "    \"INS\":       \"INS_I.xpt\",\n",
    "    \"DPQ\":       \"DPQ_I.xpt\",\n",
    "    \"SLQ\":       \"SLQ_I.xpt\",\n",
    "    \"DR1TOT\":    \"DR1TOT_I.xpt\",\n",
    "    \"DR1IFF\":    \"DR1IFF_I.xpt\",  # <-- we will EXCLUDE this later\n",
    "    \"PAQ\":       \"PAQ_I.xpt\",\n",
    "    \"BPX\":       \"BPX_I.xpt\",\n",
    "    \"BIOPRO\":    \"BIOPRO_I.xpt\",\n",
    "    \"ALB_CR\":    \"ALB_CR_I.xpt\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76b16bec-db5f-4e7d-93b7-290357c24c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading DEMO ...\n",
      "DEMO (9971, 47)\n",
      "Downloading HDL ...\n",
      "HDL (8021, 3)\n",
      "Downloading TCHOL ...\n",
      "TCHOL (8021, 3)\n",
      "Downloading TRIGLY ...\n",
      "TRIGLY (3191, 6)\n",
      "Downloading GLU ...\n",
      "GLU (3191, 4)\n",
      "Downloading INS ...\n",
      "INS (3191, 7)\n",
      "Downloading DPQ ...\n",
      "DPQ (5735, 11)\n",
      "Downloading SLQ ...\n",
      "SLQ (6327, 8)\n",
      "Downloading DR1TOT ...\n",
      "DR1TOT (9544, 168)\n",
      "Downloading DR1IFF ...\n",
      "DR1IFF (121481, 84)\n",
      "Downloading PAQ ...\n",
      "PAQ (9255, 94)\n",
      "Downloading BPX ...\n",
      "BPX (9544, 21)\n",
      "Downloading BIOPRO ...\n",
      "BIOPRO (6744, 38)\n",
      "Downloading ALB_CR ...\n",
      "ALB_CR (8608, 8)\n"
     ]
    }
   ],
   "source": [
    "all_dfs = {}\n",
    "\n",
    "for name, fname in nhanes_files.items():\n",
    "    print(f\"Downloading {name} ...\")\n",
    "    d = load_nhanes_xpt(fname, \"2015\")\n",
    "    print(name, d.shape)\n",
    "    all_dfs[name] = d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8706ba53-72d0-4c1b-bd21-976e317b24e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPED shape: (9544, 51)\n"
     ]
    }
   ],
   "source": [
    "fped, meta = pyreadstat.read_sas7bdat(\"fped_dr1tot_1516.sas7bdat\")\n",
    "print(\"FPED shape:\", fped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ca63e64-bc63-4dbb-a88b-bbc8683c6b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does merged contain DEMO columns?\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDoes merged contain DEMO columns?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRIAGENDR\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmerged\u001b[49m.columns)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRIDAGEYR\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m merged.columns)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRIDRETH3\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m merged.columns)\n",
      "\u001b[31mNameError\u001b[39m: name 'merged' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Does merged contain DEMO columns?\")\n",
    "print(\"RIAGENDR\" in merged.columns)\n",
    "print(\"RIDAGEYR\" in merged.columns)\n",
    "print(\"RIDRETH3\" in merged.columns)\n",
    "print(\"Number of columns:\", len(merged.columns))\n",
    "\n",
    "merged.columns.tolist()[:50]  # preview first 50 cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938b8f11-7e76-4fd0-acfc-414b6b153aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc1aa6d-a647-414b-8e8a-0d80f650cbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "#  FULL NHANES → FEATURE ENGINEERING → rPDQS → LONGEVITY 1.1\n",
    "# ================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0. Start from merged NHANES + FPED person-level\n",
    "# ------------------------------------------------------------\n",
    "df = merged.copy()\n",
    "\n",
    "# Merge FPED (person-level DR1TOT) onto merged NHANES\n",
    "df = df.merge(fped, on=\"SEQN\", how=\"left\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. BASIC DEMOGRAPHICS\n",
    "# ============================================================\n",
    "df[\"sex\"] = df[\"RIAGENDR\"]                     # 1=Male, 2=Female\n",
    "df[\"race_ethnicity\"] = df[\"RIDRETH3\"]\n",
    "df[\"age\"] = df[\"RIDEXAGM\"] / 12                # NHANES reports age in months\n",
    "df[\"poverty_income_ratio\"] = df[\"INDFMIN2\"]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. RENAME LAB VARIABLES\n",
    "# ============================================================\n",
    "rename_map = {\n",
    "    \"LBXGLU\": \"fasting_glucose\",\n",
    "    \"LBXIN\": \"fasting_insulin\",\n",
    "    \"LBDHDD\": \"hdl_cholesterol\",\n",
    "    \"LBDHDL\": \"hdl_cholesterol\",\n",
    "    \"LBDTCSI\": \"total_cholesterol\",\n",
    "    \"LBDTRSI\": \"triglycerides\",\n",
    "}\n",
    "df.rename(columns={k:v for k,v in rename_map.items() if k in df.columns}, inplace=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. LDL + ApoB\n",
    "# ============================================================\n",
    "def friedewald(row):\n",
    "    tg = row[\"triglycerides\"]\n",
    "    if pd.isna(tg) or tg >= 400:\n",
    "        return np.nan\n",
    "    return row[\"total_cholesterol\"] - row[\"hdl_cholesterol\"] - tg/5\n",
    "\n",
    "df[\"ldl_cholesterol\"] = df.apply(friedewald, axis=1)\n",
    "df[\"apob_est\"] = 0.65 * df[\"ldl_cholesterol\"] + 0.1 * df[\"triglycerides\"]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. HOMA-IR\n",
    "# ============================================================\n",
    "df[\"homa_ir\"] = (df[\"fasting_insulin\"] * df[\"fasting_glucose\"]) / 405\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. BLOOD PRESSURE\n",
    "# ============================================================\n",
    "sbp_cols = [c for c in df.columns if c.startswith(\"BPXSY\")]\n",
    "dbp_cols = [c for c in df.columns if c.startswith(\"BPXDI\")]\n",
    "\n",
    "df[\"sbp\"] = df[sbp_cols].mean(axis=1)\n",
    "df[\"dbp\"] = df[dbp_cols].mean(axis=1)\n",
    "df[\"pulse_pressure\"] = df[\"sbp\"] - df[\"dbp\"]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. eGFR — CKD-EPI 2021\n",
    "# ============================================================\n",
    "if \"LBXSCR\" in df.columns:\n",
    "    scr = df[\"LBXSCR\"]\n",
    "    k = np.where(df[\"sex\"] == 2, 0.7, 0.9)\n",
    "    alpha = np.where(df[\"sex\"] == 2, -0.241, -0.302)\n",
    "\n",
    "    min_part = np.minimum(scr / k, 1) ** alpha\n",
    "    max_part = np.maximum(scr / k, 1) ** -1.2\n",
    "\n",
    "    df[\"egfr\"] = 142 * min_part * max_part * (0.9938 ** df[\"age\"])\n",
    "else:\n",
    "    df[\"egfr\"] = np.nan\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7. SLEEP — SLQ030\n",
    "# ============================================================\n",
    "df[\"sleep_hours\"] = df[\"SLQ030\"]\n",
    "\n",
    "def calc_sleep_score(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    if 7 <= x <= 9: return 100\n",
    "    if 6 <= x < 7 or 9 < x <= 10: return 80\n",
    "    return 50\n",
    "\n",
    "df[\"sleep_score\"] = df[\"sleep_hours\"].apply(calc_sleep_score)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8. PHQ-9\n",
    "# ============================================================\n",
    "phq_cols = [c for c in df.columns if c.startswith(\"DPQ0\")]\n",
    "df[\"phq9_total\"] = df[phq_cols].sum(axis=1)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9. MVPA — leisure activity\n",
    "# ============================================================\n",
    "if all(c in df.columns for c in [\"PAD615\",\"PAD630\",\"PAD645\",\"PAD660\"]):\n",
    "    vig = df[\"PAD615\"] * df[\"PAD630\"]\n",
    "    mod = df[\"PAD645\"] * df[\"PAD660\"]\n",
    "    df[\"mvpa_min_week\"] = vig * 2 + mod\n",
    "else:\n",
    "    df[\"mvpa_min_week\"] = np.nan\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 10. rPDQS DIET QUALITY\n",
    "# ============================================================\n",
    "\n",
    "# --- Restrict to reliable day-1 recall\n",
    "if \"DR1DRSTZ\" in df.columns:\n",
    "    mask_bad = df[\"DR1DRSTZ\"] != 1\n",
    "else:\n",
    "    mask_bad = pd.Series(False, index=df.index)\n",
    "\n",
    "# Use FPED variables directly\n",
    "servings = df[[\n",
    "    \"SEQN\",\n",
    "    \"DR1T_V_DRKGR\",\"DR1T_V_OTHER\",\"DR1T_V_REDOR_TOMATO\",\n",
    "    \"DR1T_V_LEGUMES\",\"DR1T_G_WHOLE\",\"DR1T_G_REFINED\",\n",
    "    \"DR1T_F_OTHER\",\"DR1T_F_CITMLB\",\"DR1T_PF_NUTSDS\",\n",
    "    \"DR1T_PF_MEAT\",\"DR1T_PF_CUREDMEAT\",\n",
    "    \"DR1T_PF_SEAFD_HI\",\"DR1T_PF_SEAFD_LOW\",\n",
    "    \"DR1T_D_MILK\",\"DR1T_D_YOGURT\",\"DR1T_A_DRINKS\",\n",
    "    \"DR1T_SOLID_FATS\"\n",
    "]].copy()\n",
    "\n",
    "# Zero out unreliable recalls\n",
    "servings.loc[mask_bad, servings.columns[1:]] = np.nan\n",
    "servings.set_index(\"SEQN\", inplace=True)\n",
    "\n",
    "# Build food groups\n",
    "servings[\"dark_green_veg\"] = servings[\"DR1T_V_DRKGR\"]\n",
    "servings[\"other_veg\"] = (\n",
    "    servings[\"DR1T_V_OTHER\"] +\n",
    "    servings[\"DR1T_V_REDOR_TOMATO\"]\n",
    "    - servings[\"DR1T_V_LEGUMES\"].fillna(0)\n",
    ")\n",
    "servings[\"citrus_melons_berries\"] = servings[\"DR1T_F_CITMLB\"]\n",
    "servings[\"other_fruit\"] = servings[\"DR1T_F_OTHER\"]\n",
    "servings[\"legumes\"] = servings[\"DR1T_V_LEGUMES\"]\n",
    "servings[\"whole_grains\"] = servings[\"DR1T_G_WHOLE\"]\n",
    "servings[\"nuts_seeds\"] = servings[\"DR1T_PF_NUTSDS\"]\n",
    "servings[\"low_fat_dairy\"] = servings[\"DR1T_D_MILK\"] + servings[\"DR1T_D_YOGURT\"]\n",
    "servings[\"fish\"] = servings[\"DR1T_PF_SEAFD_HI\"] + servings[\"DR1T_PF_SEAFD_LOW\"]\n",
    "\n",
    "servings[\"red_meat\"] = servings[\"DR1T_PF_MEAT\"]\n",
    "servings[\"processed_meat\"] = servings[\"DR1T_PF_CUREDMEAT\"]\n",
    "servings[\"refined_grains\"] = servings[\"DR1T_G_REFINED\"]\n",
    "servings[\"ssb\"] = servings[\"DR1T_A_DRINKS\"]\n",
    "servings[\"fried_foods\"] = servings[\"DR1T_SOLID_FATS\"]\n",
    "\n",
    "healthy = [\"dark_green_veg\",\"other_veg\",\"citrus_melons_berries\",\"other_fruit\",\n",
    "           \"legumes\",\"whole_grains\",\"nuts_seeds\",\"low_fat_dairy\",\"fish\"]\n",
    "unhealthy = [\"red_meat\",\"processed_meat\",\"refined_grains\",\"ssb\",\"fried_foods\"]\n",
    "\n",
    "# Scoring functions\n",
    "def pos(s): return pd.qcut(s.rank(method=\"first\"), 5, labels=[0,1,2,3,4], duplicates=\"drop\").astype(float)\n",
    "def neg(s): return pd.qcut(s.rank(method=\"first\"), 5, labels=[4,3,2,1,0], duplicates=\"drop\").astype(float)\n",
    "\n",
    "for g in healthy:\n",
    "    servings[g + \"_score\"] = pos(servings[g])\n",
    "\n",
    "for g in unhealthy:\n",
    "    servings[g + \"_score\"] = neg(servings[g])\n",
    "\n",
    "score_cols = [g + \"_score\" for g in healthy + unhealthy]\n",
    "servings[\"rpdqs_total\"] = servings[score_cols].sum(axis=1)\n",
    "servings[\"rpdqs_normalized\"] = (servings[\"rpdqs_total\"] / 56) * 100\n",
    "\n",
    "df = df.merge(servings[[\"rpdqs_total\",\"rpdqs_normalized\"]],\n",
    "              left_on=\"SEQN\", right_index=True, how=\"left\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SAVE FEATURE-ENGINEERED DATASET\n",
    "# ============================================================\n",
    "df_final = df.copy()\n",
    "\n",
    "print(\"df_final shape:\", df_final.shape)\n",
    "print(df_final[[\"SEQN\",\"rpdqs_normalized\"]].head())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 11. LONGEVITY SCORE v1.1 NORMALIZATION\n",
    "# ============================================================\n",
    "\n",
    "df = df_final.copy()\n",
    "\n",
    "def normalize_positive(x, low, high):\n",
    "    return ((x - low) / (high - low)) * 100\n",
    "\n",
    "def normalize_negative(x, low, high):\n",
    "    return ((high - x) / (high - low)) * 100\n",
    "\n",
    "# BMI\n",
    "if {\"BMXWT\",\"BMXHT\"}.issubset(df.columns):\n",
    "    df[\"bmi\"] = df[\"BMXWT\"]/(df[\"BMXHT\"]/100)**2\n",
    "df[\"bmi_norm\"] = normalize_negative(df[\"bmi\"],18.5,35)\n",
    "\n",
    "# ApoB\n",
    "df[\"apob_norm\"] = normalize_negative(df[\"apob_est\"],40,120)\n",
    "\n",
    "# CRP\n",
    "df[\"crp_norm\"] = normalize_negative(df[\"LBXCRP\"],0.1,10)\n",
    "\n",
    "# PHQ-9\n",
    "df[\"phq9_norm\"] = normalize_negative(df[\"phq9_total\"],0,27)\n",
    "\n",
    "# ALT\n",
    "df[\"alt_norm\"] = normalize_negative(df[\"LBXSGPT\"],8,50)\n",
    "\n",
    "# eGFR\n",
    "df[\"egfr_norm\"] = normalize_positive(df[\"egfr\"],60,110)\n",
    "\n",
    "# MVPA\n",
    "df[\"mvpa_norm\"] = normalize_positive(df[\"mvpa_min_week\"],0,300)\n",
    "\n",
    "# Diet\n",
    "df[\"diet_norm\"] = df[\"rpdqs_normalized\"]\n",
    "\n",
    "# All other fields = NaN place-holders\n",
    "df[\"ogtt_norm\"]=np.nan\n",
    "df[\"vo2max_norm\"]=np.nan\n",
    "df[\"pack_years_norm\"]=np.nan\n",
    "df[\"moca_norm\"]=np.nan\n",
    "df[\"cac_norm\"]=np.nan\n",
    "df[\"hrv_norm\"]=np.nan\n",
    "df[\"bmd_norm\"]=np.nan\n",
    "df[\"truage_norm\"]=np.nan\n",
    "df[\"shdl_norm\"]=np.nan\n",
    "df[\"rem_norm\"]=np.nan\n",
    "df[\"grip_norm\"]=np.nan\n",
    "df[\"swls_norm\"]=np.nan\n",
    "\n",
    "# Final 20 variables\n",
    "longevity_inputs=[\n",
    "\"ogtt_norm\",\"apob_norm\",\"vo2max_norm\",\"crp_norm\",\"bmi_norm\",\n",
    "\"pack_years_norm\",\"moca_norm\",\"mvpa_norm\",\"cac_norm\",\"hrv_norm\",\n",
    "\"phq9_norm\",\"alt_norm\",\"egfr_norm\",\"bmd_norm\",\"truage_norm\",\n",
    "\"shdl_norm\",\"rem_norm\",\"grip_norm\",\"swls_norm\",\"diet_norm\"\n",
    "]\n",
    "\n",
    "df_longevity = df[[\"SEQN\"]+longevity_inputs]\n",
    "print(df_longevity.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f21a8-6328-490a-86f5-43bb2bcf3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from DEMO (person-level gold standard)\n",
    "df = all_dfs[\"DEMO\"].copy()\n",
    "\n",
    "# merge all other person-level NHANES datasets except DR1IFF\n",
    "for name, d in all_dfs.items():\n",
    "    if name in [\"DEMO\", \"DR1IFF\"]:   # exclude DEMO (already loaded) and DR1IFF (food item file)\n",
    "        continue\n",
    "    df = df.merge(d, on=\"SEQN\", how=\"left\")\n",
    "\n",
    "# merge FPED food-group data\n",
    "df = df.merge(fped, on=\"SEQN\", how=\"left\")\n",
    "\n",
    "print(\"Merged person-level shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6faf3-5d4d-4e33-9741-b1682dded14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# SAFELY assign sex and age\n",
    "# ---------------------------\n",
    "\n",
    "# --- SEX ---\n",
    "if \"sex\" in df.columns:\n",
    "    # already present (from rename or earlier merge)\n",
    "    df[\"sex\"] = df[\"sex\"]\n",
    "elif \"RIAGENDR\" in df.columns:\n",
    "    df[\"sex\"] = df[\"RIAGENDR\"]\n",
    "elif \"RIAGENDER\" in df.columns:\n",
    "    df[\"sex\"] = df[\"RIAGENDER\"]\n",
    "elif \"RIAGENDR_x\" in df.columns:\n",
    "    df[\"sex\"] = df[\"RIAGENDR_x\"]\n",
    "elif \"RIAGENDR_y\" in df.columns:\n",
    "    df[\"sex\"] = df[\"RIAGENDR_y\"]\n",
    "else:\n",
    "    print(\"⚠️ WARNING: No sex variable found. Assigning NaN.\")\n",
    "    df[\"sex\"] = np.nan\n",
    "\n",
    "# --- AGE ---\n",
    "if \"age\" in df.columns:\n",
    "    df[\"age\"] = df[\"age\"]\n",
    "elif \"RIDAGEYR\" in df.columns:\n",
    "    df[\"age\"] = df[\"RIDAGEYR\"]\n",
    "elif \"RIDAGEYR_x\" in df.columns:\n",
    "    df[\"age\"] = df[\"RIDAGEYR_x\"]\n",
    "elif \"RIDAGEYR_y\" in df.columns:\n",
    "    df[\"age\"] = df[\"RIDAGEYR_y\"]\n",
    "elif \"RIDAGEY\" in df.columns:  # some cycles\n",
    "    df[\"age\"] = df[\"RIDAGEY\"]\n",
    "else:\n",
    "    print(\"⚠️ WARNING: No age variable found. Assigning NaN.\")\n",
    "    df[\"age\"] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022e6183-6b83-459a-a3d7-f1dde4d768cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "#  FULL NHANES → FEATURE ENGINEERING → rPDQS → LONGEVITY 1.1\n",
    "# ================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0. Start from merged NHANES + FPED person-level\n",
    "# ------------------------------------------------------------\n",
    "df = merged.copy()\n",
    "\n",
    "# Merge FPED (person-level DR1TOT) onto merged NHANES\n",
    "df = df.merge(fped, on=\"SEQN\", how=\"left\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. BASIC DEMOGRAPHICS\n",
    "# ============================================================\n",
    "df[\"sex\"] = df[\"RIAGENDR\"]                     # 1=Male, 2=Female\n",
    "df[\"race_ethnicity\"] = df[\"RIDRETH3\"]\n",
    "df[\"age\"] = df[\"RIDEXAGM\"] / 12                # NHANES reports age in months\n",
    "df[\"poverty_income_ratio\"] = df[\"INDFMIN2\"]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. RENAME LAB VARIABLES\n",
    "# ============================================================\n",
    "rename_map = {\n",
    "    \"LBXGLU\": \"fasting_glucose\",\n",
    "    \"LBXIN\": \"fasting_insulin\",\n",
    "    \"LBDHDD\": \"hdl_cholesterol\",\n",
    "    \"LBDHDL\": \"hdl_cholesterol\",\n",
    "    \"LBDTCSI\": \"total_cholesterol\",\n",
    "    \"LBDTRSI\": \"triglycerides\",\n",
    "}\n",
    "df.rename(columns={k:v for k,v in rename_map.items() if k in df.columns}, inplace=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. LDL + ApoB\n",
    "# ============================================================\n",
    "def friedewald(row):\n",
    "    tg = row[\"triglycerides\"]\n",
    "    if pd.isna(tg) or tg >= 400:\n",
    "        return np.nan\n",
    "    return row[\"total_cholesterol\"] - row[\"hdl_cholesterol\"] - tg/5\n",
    "\n",
    "df[\"ldl_cholesterol\"] = df.apply(friedewald, axis=1)\n",
    "df[\"apob_est\"] = 0.65 * df[\"ldl_cholesterol\"] + 0.1 * df[\"triglycerides\"]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. HOMA-IR\n",
    "# ============================================================\n",
    "df[\"homa_ir\"] = (df[\"fasting_insulin\"] * df[\"fasting_glucose\"]) / 405\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. BLOOD PRESSURE\n",
    "# ============================================================\n",
    "sbp_cols = [c for c in df.columns if c.startswith(\"BPXSY\")]\n",
    "dbp_cols = [c for c in df.columns if c.startswith(\"BPXDI\")]\n",
    "\n",
    "df[\"sbp\"] = df[sbp_cols].mean(axis=1)\n",
    "df[\"dbp\"] = df[dbp_cols].mean(axis=1)\n",
    "df[\"pulse_pressure\"] = df[\"sbp\"] - df[\"dbp\"]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. eGFR — CKD-EPI 2021\n",
    "# ============================================================\n",
    "if \"LBXSCR\" in df.columns:\n",
    "    scr = df[\"LBXSCR\"]\n",
    "    k = np.where(df[\"sex\"] == 2, 0.7, 0.9)\n",
    "    alpha = np.where(df[\"sex\"] == 2, -0.241, -0.302)\n",
    "\n",
    "    min_part = np.minimum(scr / k, 1) ** alpha\n",
    "    max_part = np.maximum(scr / k, 1) ** -1.2\n",
    "\n",
    "    df[\"egfr\"] = 142 * min_part * max_part * (0.9938 ** df[\"age\"])\n",
    "else:\n",
    "    df[\"egfr\"] = np.nan\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7. SLEEP — SLQ030\n",
    "# ============================================================\n",
    "df[\"sleep_hours\"] = df[\"SLQ030\"]\n",
    "\n",
    "def calc_sleep_score(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    if 7 <= x <= 9: return 100\n",
    "    if 6 <= x < 7 or 9 < x <= 10: return 80\n",
    "    return 50\n",
    "\n",
    "df[\"sleep_score\"] = df[\"sleep_hours\"].apply(calc_sleep_score)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8. PHQ-9\n",
    "# ============================================================\n",
    "phq_cols = [c for c in df.columns if c.startswith(\"DPQ0\")]\n",
    "df[\"phq9_total\"] = df[phq_cols].sum(axis=1)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9. MVPA — leisure activity\n",
    "# ============================================================\n",
    "if all(c in df.columns for c in [\"PAD615\",\"PAD630\",\"PAD645\",\"PAD660\"]):\n",
    "    vig = df[\"PAD615\"] * df[\"PAD630\"]\n",
    "    mod = df[\"PAD645\"] * df[\"PAD660\"]\n",
    "    df[\"mvpa_min_week\"] = vig * 2 + mod\n",
    "else:\n",
    "    df[\"mvpa_min_week\"] = np.nan\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 10. rPDQS DIET QUALITY\n",
    "# ============================================================\n",
    "\n",
    "# --- Restrict to reliable day-1 recall\n",
    "if \"DR1DRSTZ\" in df.columns:\n",
    "    mask_bad = df[\"DR1DRSTZ\"] != 1\n",
    "else:\n",
    "    mask_bad = pd.Series(False, index=df.index)\n",
    "\n",
    "# Use FPED variables directly\n",
    "servings = df[[\n",
    "    \"SEQN\",\n",
    "    \"DR1T_V_DRKGR\",\"DR1T_V_OTHER\",\"DR1T_V_REDOR_TOMATO\",\n",
    "    \"DR1T_V_LEGUMES\",\"DR1T_G_WHOLE\",\"DR1T_G_REFINED\",\n",
    "    \"DR1T_F_OTHER\",\"DR1T_F_CITMLB\",\"DR1T_PF_NUTSDS\",\n",
    "    \"DR1T_PF_MEAT\",\"DR1T_PF_CUREDMEAT\",\n",
    "    \"DR1T_PF_SEAFD_HI\",\"DR1T_PF_SEAFD_LOW\",\n",
    "    \"DR1T_D_MILK\",\"DR1T_D_YOGURT\",\"DR1T_A_DRINKS\",\n",
    "    \"DR1T_SOLID_FATS\"\n",
    "]].copy()\n",
    "\n",
    "# Zero out unreliable recalls\n",
    "servings.loc[mask_bad, servings.columns[1:]] = np.nan\n",
    "servings.set_index(\"SEQN\", inplace=True)\n",
    "\n",
    "# Build food groups\n",
    "servings[\"dark_green_veg\"] = servings[\"DR1T_V_DRKGR\"]\n",
    "servings[\"other_veg\"] = (\n",
    "    servings[\"DR1T_V_OTHER\"] +\n",
    "    servings[\"DR1T_V_REDOR_TOMATO\"]\n",
    "    - servings[\"DR1T_V_LEGUMES\"].fillna(0)\n",
    ")\n",
    "servings[\"citrus_melons_berries\"] = servings[\"DR1T_F_CITMLB\"]\n",
    "servings[\"other_fruit\"] = servings[\"DR1T_F_OTHER\"]\n",
    "servings[\"legumes\"] = servings[\"DR1T_V_LEGUMES\"]\n",
    "servings[\"whole_grains\"] = servings[\"DR1T_G_WHOLE\"]\n",
    "servings[\"nuts_seeds\"] = servings[\"DR1T_PF_NUTSDS\"]\n",
    "servings[\"low_fat_dairy\"] = servings[\"DR1T_D_MILK\"] + servings[\"DR1T_D_YOGURT\"]\n",
    "servings[\"fish\"] = servings[\"DR1T_PF_SEAFD_HI\"] + servings[\"DR1T_PF_SEAFD_LOW\"]\n",
    "\n",
    "servings[\"red_meat\"] = servings[\"DR1T_PF_MEAT\"]\n",
    "servings[\"processed_meat\"] = servings[\"DR1T_PF_CUREDMEAT\"]\n",
    "servings[\"refined_grains\"] = servings[\"DR1T_G_REFINED\"]\n",
    "servings[\"ssb\"] = servings[\"DR1T_A_DRINKS\"]\n",
    "servings[\"fried_foods\"] = servings[\"DR1T_SOLID_FATS\"]\n",
    "\n",
    "healthy = [\"dark_green_veg\",\"other_veg\",\"citrus_melons_berries\",\"other_fruit\",\n",
    "           \"legumes\",\"whole_grains\",\"nuts_seeds\",\"low_fat_dairy\",\"fish\"]\n",
    "unhealthy = [\"red_meat\",\"processed_meat\",\"refined_grains\",\"ssb\",\"fried_foods\"]\n",
    "\n",
    "# Scoring functions\n",
    "def pos(s): return pd.qcut(s.rank(method=\"first\"), 5, labels=[0,1,2,3,4], duplicates=\"drop\").astype(float)\n",
    "def neg(s): return pd.qcut(s.rank(method=\"first\"), 5, labels=[4,3,2,1,0], duplicates=\"drop\").astype(float)\n",
    "\n",
    "for g in healthy:\n",
    "    servings[g + \"_score\"] = pos(servings[g])\n",
    "\n",
    "for g in unhealthy:\n",
    "    servings[g + \"_score\"] = neg(servings[g])\n",
    "\n",
    "score_cols = [g + \"_score\" for g in healthy + unhealthy]\n",
    "servings[\"rpdqs_total\"] = servings[score_cols].sum(axis=1)\n",
    "servings[\"rpdqs_normalized\"] = (servings[\"rpdqs_total\"] / 56) * 100\n",
    "\n",
    "df = df.merge(servings[[\"rpdqs_total\",\"rpdqs_normalized\"]],\n",
    "              left_on=\"SEQN\", right_index=True, how=\"left\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SAVE FEATURE-ENGINEERED DATASET\n",
    "# ============================================================\n",
    "df_final = df.copy()\n",
    "\n",
    "print(\"df_final shape:\", df_final.shape)\n",
    "print(df_final[[\"SEQN\",\"rpdqs_normalized\"]].head())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 11. LONGEVITY SCORE v1.1 NORMALIZATION\n",
    "# ============================================================\n",
    "\n",
    "df = df_final.copy()\n",
    "\n",
    "def normalize_positive(x, low, high):\n",
    "    return ((x - low) / (high - low)) * 100\n",
    "\n",
    "def normalize_negative(x, low, high):\n",
    "    return ((high - x) / (high - low)) * 100\n",
    "\n",
    "# BMI\n",
    "if {\"BMXWT\",\"BMXHT\"}.issubset(df.columns):\n",
    "    df[\"bmi\"] = df[\"BMXWT\"]/(df[\"BMXHT\"]/100)**2\n",
    "df[\"bmi_norm\"] = normalize_negative(df[\"bmi\"],18.5,35)\n",
    "\n",
    "# ApoB\n",
    "df[\"apob_norm\"] = normalize_negative(df[\"apob_est\"],40,120)\n",
    "\n",
    "# CRP\n",
    "df[\"crp_norm\"] = normalize_negative(df[\"LBXCRP\"],0.1,10)\n",
    "\n",
    "# PHQ-9\n",
    "df[\"phq9_norm\"] = normalize_negative(df[\"phq9_total\"],0,27)\n",
    "\n",
    "# ALT\n",
    "df[\"alt_norm\"] = normalize_negative(df[\"LBXSGPT\"],8,50)\n",
    "\n",
    "# eGFR\n",
    "df[\"egfr_norm\"] = normalize_positive(df[\"egfr\"],60,110)\n",
    "\n",
    "# MVPA\n",
    "df[\"mvpa_norm\"] = normalize_positive(df[\"mvpa_min_week\"],0,300)\n",
    "\n",
    "# Diet\n",
    "df[\"diet_norm\"] = df[\"rpdqs_normalized\"]\n",
    "\n",
    "# All other fields = NaN place-holders\n",
    "df[\"ogtt_norm\"]=np.nan\n",
    "df[\"vo2max_norm\"]=np.nan\n",
    "df[\"pack_years_norm\"]=np.nan\n",
    "df[\"moca_norm\"]=np.nan\n",
    "df[\"cac_norm\"]=np.nan\n",
    "df[\"hrv_norm\"]=np.nan\n",
    "df[\"bmd_norm\"]=np.nan\n",
    "df[\"truage_norm\"]=np.nan\n",
    "df[\"shdl_norm\"]=np.nan\n",
    "df[\"rem_norm\"]=np.nan\n",
    "df[\"grip_norm\"]=np.nan\n",
    "df[\"swls_norm\"]=np.nan\n",
    "\n",
    "# Final 20 variables\n",
    "longevity_inputs=[\n",
    "\"ogtt_norm\",\"apob_norm\",\"vo2max_norm\",\"crp_norm\",\"bmi_norm\",\n",
    "\"pack_years_norm\",\"moca_norm\",\"mvpa_norm\",\"cac_norm\",\"hrv_norm\",\n",
    "\"phq9_norm\",\"alt_norm\",\"egfr_norm\",\"bmd_norm\",\"truage_norm\",\n",
    "\"shdl_norm\",\"rem_norm\",\"grip_norm\",\"swls_norm\",\"diet_norm\"\n",
    "]\n",
    "\n",
    "df_longevity = df[[\"SEQN\"]+longevity_inputs]\n",
    "print(df_longevity.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cd2647-cbdd-4b29-b05a-ac54763078d4",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5943e44a-b8d1-42eb-9bf8-d991b7b5ee93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a32bc8d-b147-4378-8ac5-f42af4978852",
   "metadata": {},
   "source": [
    "# build rPDQS score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf46bd-706a-4a29-9c2b-81d66e0e7cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fped.columns[:20]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b524c30-a114-4f8f-8cc1-90d23c05efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DR1DRSTZ\"].value_counts(dropna=False).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3794cc-98c8-4a31-9a93-3b228b58b1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53f38e-177b-4f6d-9da1-a0221d645268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77000153-d480-4d07-ba97-33561e7ee6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ==========================================================\n",
    "# 1. Extract DR1IFF (food-item level file)\n",
    "# ==========================================================\n",
    "dr1 = all_dfs[\"DR1IFF\"].copy()\n",
    "\n",
    "# Keep only necessary columns\n",
    "needed_cols = [\"SEQN\", \"DR1IFDCD\", \"DR1IGRMS\"]\n",
    "missing_cols = [c for c in needed_cols if c not in dr1.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing columns required for rPDQS: {missing_cols}\")\n",
    "\n",
    "dr1 = dr1[needed_cols].copy()\n",
    "\n",
    "# ==========================================================\n",
    "# 2. Create the FPED 4-digit food-group code\n",
    "# ==========================================================\n",
    "dr1[\"fg_code\"] = (dr1[\"DR1IFDCD\"] // 10000).astype(\"Int64\")\n",
    "\n",
    "# ==========================================================\n",
    "# 3. Official rPDQS food-group map\n",
    "# ==========================================================\n",
    "rpdqs_map = {\n",
    "    \"dark_green_veg\":       [6310, 6320],\n",
    "    \"other_veg\":            [6110, 6120, 6130, 6140],\n",
    "    \"citrus_melons_berries\":[6210, 6220, 6230],\n",
    "    \"other_fruit\":          [6240, 6250],\n",
    "    \"legumes\":              [7510],\n",
    "    \"whole_grains\":         [5710, 5720],\n",
    "    \"nuts_seeds\":           [7410, 7420],\n",
    "    \"low_fat_dairy\":        [1310, 1320],\n",
    "    \"fish\":                 [2710, 2720],\n",
    "\n",
    "    # Negative food groups\n",
    "    \"red_meat\":             [2510, 2520],\n",
    "    \"processed_meat\":       [2530, 2540],\n",
    "    \"refined_grains\":       [5610, 5620],\n",
    "    \"ssb\":                  [9310, 9320, 9330],\n",
    "    \"fried_foods\":          [6410, 6420]\n",
    "}\n",
    "\n",
    "# ==========================================================\n",
    "# 4. Map each fg_code → rPDQS category\n",
    "# ==========================================================\n",
    "reverse_map = {code: group for group, codes in rpdqs_map.items() for code in codes}\n",
    "\n",
    "def classify_food(code):\n",
    "    return reverse_map.get(code, None)\n",
    "\n",
    "dr1[\"rpdqs_cat\"] = dr1[\"fg_code\"].apply(classify_food)\n",
    "\n",
    "# Drop rows not part of rPDQS\n",
    "dr1 = dr1.dropna(subset=[\"rpdqs_cat\"])\n",
    "\n",
    "# ==========================================================\n",
    "# 5. Compute total grams per category per SEQN\n",
    "# ==========================================================\n",
    "servings = (\n",
    "    dr1.groupby([\"SEQN\", \"rpdqs_cat\"])[\"DR1IGRMS\"]\n",
    "       .sum()\n",
    "       .unstack()\n",
    "       .fillna(0)\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# 6. Safe quintile scoring function\n",
    "# ==========================================================\n",
    "def safe_qcut(series, labels):\n",
    "    s = series.fillna(0)\n",
    "\n",
    "    try:\n",
    "        q = pd.qcut(s, 5, labels=labels, duplicates=\"drop\")\n",
    "        # if bins collapse (common), fallback:\n",
    "        if len(q.cat.categories) != len(labels):\n",
    "            return pd.Series([labels[0]] * len(s), index=s.index, dtype=float)\n",
    "        return q.astype(float)\n",
    "    except Exception:\n",
    "        # if all zeros or qcut cannot run:\n",
    "        return pd.Series([labels[0]] * len(s), index=s.index, dtype=float)\n",
    "\n",
    "# ==========================================================\n",
    "# 7. Apply scoring rules\n",
    "# ==========================================================\n",
    "positive = [\n",
    "    \"dark_green_veg\",\"other_veg\",\"citrus_melons_berries\",\"other_fruit\",\n",
    "    \"legumes\",\"whole_grains\",\"nuts_seeds\",\"low_fat_dairy\",\"fish\"\n",
    "]\n",
    "\n",
    "negative = [\"red_meat\",\"processed_meat\",\"refined_grains\",\"ssb\",\"fried_foods\"]\n",
    "\n",
    "# Positive groups: 0 → 4\n",
    "for col in positive:\n",
    "    if col in servings.columns:\n",
    "        servings[col + \"_score\"] = safe_qcut(servings[col], labels=[0,1,2,3,4])\n",
    "    else:\n",
    "        servings[col + \"_score\"] = 0\n",
    "\n",
    "# Negative groups: 4 → 0\n",
    "for col in negative:\n",
    "    if col in servings.columns:\n",
    "        servings[col + \"_score\"] = safe_qcut(servings[col], labels=[4,3,2,1,0])\n",
    "    else:\n",
    "        servings[col + \"_score\"] = 0\n",
    "\n",
    "# ==========================================================\n",
    "# 8. Total rPDQS and normalized score (0–100)\n",
    "# ==========================================================\n",
    "score_cols = [c for c in servings.columns if c.endswith(\"_score\")]\n",
    "\n",
    "servings[\"rpdqs_total\"] = servings[score_cols].sum(axis=1)\n",
    "\n",
    "servings[\"rpdqs_normalized\"] = (\n",
    "    servings[\"rpdqs_total\"] / (len(score_cols) * 4) * 100\n",
    ")\n",
    "# Remove any previous rPDQS columns before re-merging\n",
    "df = df.drop(columns=[c for c in df.columns if c in [\"rpdqs_total\",\"rpdqs_normalized\"]], errors=\"ignore\")\n",
    "\n",
    "# Merge rPDQS results back into df\n",
    "df = df.merge(\n",
    "    servings[[\"rpdqs_total\", \"rpdqs_normalized\"]],\n",
    "    left_on=\"SEQN\", right_index=True, how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"✓ rPDQS columns now present:\",\n",
    "      \"rpdqs_total\" in df.columns,\n",
    "      \"rpdqs_normalized\" in df.columns)\n",
    "\n",
    "print(df[[\"SEQN\",\"rpdqs_total\",\"rpdqs_normalized\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be1db92-f71b-4ae5-9eef-e69f998b4425",
   "metadata": {},
   "source": [
    "## build BMI and normalize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a73771d-197f-4d17-9e3d-dbe0ae21fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Longevity Score v1.1: Compute & Normalize all components\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "df = df_final.copy()\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 1. BMI\n",
    "# -----------------------\n",
    "# NHANES variables:\n",
    "# BMXWT = weight in kg\n",
    "# BMXHT = height in cm\n",
    "if {\"BMXWT\", \"BMXHT\"}.issubset(df.columns):\n",
    "    df[\"bmi\"] = df[\"BMXWT\"] / (df[\"BMXHT\"] / 100)**2\n",
    "else:\n",
    "    df[\"bmi\"] = np.nan\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 2. Normalize key domains\n",
    "#    Each normalization maps raw values → 0–100 scale\n",
    "# -----------------------\n",
    "\n",
    "def normalize_positive(x, low, high):\n",
    "    \"\"\"Higher is better.\"\"\"\n",
    "    return ((x - low) / (high - low)) * 100\n",
    "\n",
    "def normalize_negative(x, low, high):\n",
    "    \"\"\"Lower is better (e.g., CRP, ApoB, BMI).\"\"\"\n",
    "    return ((high - x) / (high - low)) * 100\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# VO2max — NHANES DOES NOT HAVE\n",
    "# Placeholder = NaN\n",
    "# -----------------------\n",
    "df[\"vo2max_raw\"] = np.nan\n",
    "df[\"vo2max_norm\"] = np.nan\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 2-hour OGTT — not in NHANES\n",
    "# -----------------------\n",
    "df[\"ogtt_raw\"] = np.nan\n",
    "df[\"ogtt_norm\"] = np.nan\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# ApoB (estimated)\n",
    "# -----------------------\n",
    "if \"apob_est\" in df.columns:\n",
    "    df[\"apob_norm\"] = normalize_negative(df[\"apob_est\"], low=40, high=120)\n",
    "else:\n",
    "    df[\"apob_norm\"] = np.nan\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# CRP (NHANES variable: LBXCRP)\n",
    "# -----------------------\n",
    "if \"LBXCRP\" in df.columns:\n",
    "    df[\"crp_norm\"] = normalize_negative(df[\"LBXCRP\"], low=0.1, high=10)\n",
    "else:\n",
    "    df[\"crp_norm\"] = np.nan\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# BMI\n",
    "# -----------------------\n",
    "df[\"bmi_norm\"] = normalize_negative(df[\"bmi\"], low=18.5, high=35)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Smoking (pack-years)\n",
    "# NHANES has: SMQ020 (ever smoked), SMD641 (years smoked)\n",
    "# We estimate pack-years crudely.\n",
    "# -----------------------\n",
    "if {\"SMD630\", \"SMD641\"}.issubset(df.columns):\n",
    "    df[\"cigs_per_day\"] = df[\"SMD630\"]\n",
    "    df[\"years_smoked\"] = df[\"SMD641\"]\n",
    "    df[\"pack_years\"] = (df[\"cigs_per_day\"] / 20) * df[\"years_smoked\"]\n",
    "    df[\"pack_years_norm\"] = normalize_negative(df[\"pack_years\"], low=0, high=50)\n",
    "else:\n",
    "    df[\"pack_years_norm\"] = np.nan\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Cognitive function — MoCA not in NHANES\n",
    "# -----------------------\n",
    "df[\"moca_norm\"] = np.nan\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# MVPA (already computed)\n",
    "# -----------------------\n",
    "if \"mvpa_min_week\" in df.columns:\n",
    "    df[\"mvpa_norm\"] = normalize_positive(df[\"mvpa_min_week\"], low=0, high=300)\n",
    "else:\n",
    "    df[\"mvpa_norm\"] = np.nan\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# CAC — not in NHANES\n",
    "# -----------------------\n",
    "df[\"cac_norm\"] = np.nan\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# HRV — not in NHANES\n",
    "# -----------------------\n",
    "df[\"hrv_norm\"] = np.nan\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# PHQ-9 mental health\n",
    "# -----------------------\n",
    "df[\"phq9_norm\"] = normalize_negative(df[\"phq9_total\"], low=0, high=27)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# ALT (liver enzyme)\n",
    "# NHANES variable: LBXSGPT\n",
    "# -----------------------\n",
    "if \"LBXSGPT\" in df.columns:\n",
    "    df[\"alt_norm\"] = normalize_negative(df[\"LBXSGPT\"], low=8, high=50)\n",
    "else:\n",
    "    df[\"alt_norm\"] = np.nan\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# eGFR\n",
    "# -----------------------\n",
    "df[\"egfr_norm\"] = normalize_positive(df[\"egfr\"], low=60, high=110)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Bone Mineral Density — NHANES has DEXA data but not in your load\n",
    "# -----------------------\n",
    "df[\"bmd_norm\"] = np.nan\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Epigenetic Age (TruAge) — not in NHANES\n",
    "# -----------------------\n",
    "df[\"truage_norm\"] = np.nan\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Small HDL particles — not in NHANES\n",
    "# -----------------------\n",
    "df[\"shdl_norm\"] = np.nan\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# REM sleep — not in NHANES\n",
    "# -----------------------\n",
    "df[\"rem_norm\"] = np.nan\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Grip strength — NHANES variable exists (MGDCGSZ)\n",
    "# We will check and normalize\n",
    "# -----------------------\n",
    "grip_vars = [c for c in df.columns if \"MGDC\" in c]\n",
    "if grip_vars:\n",
    "    df[\"grip_strength\"] = df[grip_vars].max(axis=1)\n",
    "    df[\"grip_norm\"] = normalize_positive(df[\"grip_strength\"], low=10, high=60)\n",
    "else:\n",
    "    df[\"grip_norm\"] = np.nan\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Life Satisfaction (SWLS) — not in NHANES\n",
    "# -----------------------\n",
    "df[\"swls_norm\"] = np.nan\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Diet quality (rPDQS, already computed)\n",
    "# -----------------------\n",
    "df[\"diet_norm\"] = df[\"rpdqs_normalized\"]   # already 0–100\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Final Longevity Score v1.1 inputs only\n",
    "# -----------------------\n",
    "longevity_inputs = [\n",
    "    \"ogtt_norm\",\"apob_norm\",\"vo2max_norm\",\"crp_norm\",\"bmi_norm\",\n",
    "    \"pack_years_norm\",\"moca_norm\",\"mvpa_norm\",\"cac_norm\",\"hrv_norm\",\n",
    "    \"phq9_norm\",\"alt_norm\",\"egfr_norm\",\"bmd_norm\",\"truage_norm\",\n",
    "    \"shdl_norm\",\"rem_norm\",\"grip_norm\",\"swls_norm\",\"diet_norm\"\n",
    "]\n",
    "\n",
    "df_longevity = df[[\"SEQN\"] + longevity_inputs]\n",
    "\n",
    "print(\"Longevity variable matrix shape:\", df_longevity.shape)\n",
    "df_longevity.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0e17b5-c3c4-4f04-8ab4-0869728536a6",
   "metadata": {},
   "source": [
    "## exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5338bedc-4ef1-4f0a-a374-fcc443026c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b14e365-5676-413d-b95b-a4b6c8f7581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf944146-75c4-4c09-b98b-e7f987e709c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9065b050-27c2-4361-a761-30a5fc19fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea1a7db-a381-4cb9-a755-2ea80204b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why are some rPDQS missing?\n",
    "\n",
    "df_final.loc[df_final['rpdqs_cat'].isna(), ['SEQN','DR1DRSTZ','RIDAGEYR','WTDR2D']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3957de6d-bb05-4498-82fb-04ba16db079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad315a-d7fe-479f-b99c-afb973526cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f231aa-8eb1-4231-ac9a-41d39e8cd4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rpdqs.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e28075-755a-4039-b37e-dc8b40cea85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "[df_name for df_name in dir() if isinstance(eval(df_name), pd.DataFrame)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b2cede-a4ca-432b-9ecd-d4bc408c1db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fped.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46617bc-c562-4ab1-9158-c58e294ed822",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656d83ca-a14e-4907-aa87-e0d055a45715",
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_table.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e323b51-c8cf-462b-8e42-d040ddd03bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['SEQN'].isin(fped['SEQN']).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40a019e-6ff8-4700-b03c-0d020733e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fped['DR1DRSTZ'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeb2a21-c9c2-47ab-9c96-6e2a18b08fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[~df_final['SEQN'].isin(fped['SEQN'])]['SEQN'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42b954d-4ec7-4dbe-98ff-2825b4473f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fped.loc[fped['SEQN'].isin([83758,83771,83782,83846,83850])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78788ca-9969-4cb8-a8c9-43579ab611da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.loc[df_final['SEQN'].isin([83758,83771,83782,83846,83850]),\n",
    "             ['SEQN','rpdqs_total','rpdqs_cat']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd6866-6d2c-4dce-adcd-026b9e86559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fped[fped['SEQN'].isin([83758,83771,83782,83846,83850])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7296aa-2078-4407-b94a-2e130fd21bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpdqs_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1055865-9a57-42a6-8ebe-582a4dc53e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqns = [83758, 83771, 83782, 83846, 83850]\n",
    "\n",
    "fped.loc[fped['SEQN'].isin(seqns)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162f681f-18d1-4546-a018-5ba90cc41c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in dir():\n",
    "    if \"map\" in obj.lower():\n",
    "        print(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfde9a5d-ada0-4a17-9e8a-487209c9c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc3edb4-ceab-401c-9a79-9c5f83cbe6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpdqs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc233408-6e43-4d05-a954-ad393d52d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "[x for x in dir() if isinstance(eval(x), dict)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51060a90-0638-408c-9f79-27b103eb5d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for i, cell in enumerate(In):\n",
    "    if re.search(r'rpdqs_cat', cell, flags=re.IGNORECASE):\n",
    "        print(f\"Cell {i}:\")\n",
    "        print(cell)\n",
    "        print(\"-----\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
