{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc142f9f-ea28-4c55-b2cf-4de247b3daa7",
   "metadata": {},
   "source": [
    "# Imports + Cache Loader + Cycle Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1c52efc-d459-4894-b0b7-28ed645adc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pyreadstat\n",
    "\n",
    "# Cache directory\n",
    "CACHE_DIR = \"nhanes_cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------\n",
    "# Helper: Load NHANES XPT with caching\n",
    "# ---------------------------------------\n",
    "def load_nhanes_xpt(filename: str, year: str):\n",
    "    local_path = os.path.join(CACHE_DIR, f\"{year}_{filename}\")\n",
    "\n",
    "    if os.path.exists(local_path):\n",
    "        df, meta = pyreadstat.read_xport(local_path)\n",
    "        return df\n",
    "\n",
    "    url = f\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/{year}/DataFiles/{filename}\"\n",
    "    r = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "\n",
    "    if r.status_code == 404:\n",
    "        print(f\"Missing: {filename} for {year}\")\n",
    "        return None\n",
    "\n",
    "    with open(local_path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "    df, meta = pyreadstat.read_xport(local_path)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# Cycle file dictionaries (2011–2018)\n",
    "# ---------------------------------------\n",
    "def cycle(year, suffix):\n",
    "    return {\n",
    "        \"DEMO\":   f\"DEMO_{suffix}.xpt\",\n",
    "        \"HDL\":    f\"HDL_{suffix}.xpt\",\n",
    "        \"TCHOL\":  f\"TCHOL_{suffix}.xpt\",\n",
    "        \"TRIGLY\": f\"TRIGLY_{suffix}.xpt\",\n",
    "        \"GLU\":    f\"GLU_{suffix}.xpt\",\n",
    "        \"INS\":    f\"INS_{suffix}.xpt\" if suffix != \"G\" else \"GLU_G.xpt\",\n",
    "        \"DPQ\":    f\"DPQ_{suffix}.xpt\",\n",
    "        \"SLQ\":    f\"SLQ_{suffix}.xpt\",\n",
    "        \"DR1TOT\": f\"DR1TOT_{suffix}.xpt\",\n",
    "        \"PAQ\":    f\"PAQ_{suffix}.xpt\",\n",
    "        \"BPX\":    f\"BPX_{suffix}.xpt\",\n",
    "        \"BIOPRO\": f\"BIOPRO_{suffix}.xpt\",      # ALT/AST in some cycles\n",
    "        \"ALB_CR\": f\"ALB_CR_{suffix}.xpt\",\n",
    "        \"BMX\":    f\"BMX_{suffix}.xpt\",          # BMI/waist\n",
    "        \"CBC\":    f\"CBC_{suffix}.xpt\",\n",
    "    }\n",
    "\n",
    "all_cycles = {\n",
    "    \"2011\": cycle(\"2011\", \"G\"),\n",
    "    \"2013\": cycle(\"2013\", \"H\"),\n",
    "    \"2015\": cycle(\"2015\", \"I\"),\n",
    "    \"2017\": cycle(\"2017\", \"J\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eb3089-aefa-4c9b-886f-a79c9168387d",
   "metadata": {},
   "source": [
    "# Merge NHANES Cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da8340fe-613e-4572-b7dc-be5497c4efde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cycle 2011 ...\n",
      "Loading cycle 2013 ...\n",
      "Loading cycle 2015 ...\n",
      "Loading cycle 2017 ...\n",
      "Merged NHANES shape: (39156, 495)\n"
     ]
    }
   ],
   "source": [
    "def load_cycle(files: dict, year: str):\n",
    "    dfs = []\n",
    "    for name, fname in files.items():\n",
    "        d = load_nhanes_xpt(fname, year)\n",
    "        if d is not None:\n",
    "            dfs.append(d)\n",
    "\n",
    "    if not dfs:\n",
    "        return None\n",
    "\n",
    "    merged = dfs[0]\n",
    "    for d in dfs[1:]:\n",
    "        merged = merged.merge(d, on=\"SEQN\", how=\"outer\")\n",
    "\n",
    "    merged[\"CYCLE\"] = year\n",
    "    return merged\n",
    "\n",
    "\n",
    "df_list = []\n",
    "for yr, files in all_cycles.items():\n",
    "    print(f\"Loading cycle {yr} ...\")\n",
    "    out = load_cycle(files, yr)\n",
    "    if out is not None:\n",
    "        df_list.append(out)\n",
    "\n",
    "df_all = pd.concat(df_list, ignore_index=True)\n",
    "print(\"Merged NHANES shape:\", df_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6026d83d-c6b9-4314-b0ae-f2a217418878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>RIDSTATR</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>RIDAGEMN</th>\n",
       "      <th>RIDRETH1</th>\n",
       "      <th>RIDRETH3</th>\n",
       "      <th>RIDEXMON</th>\n",
       "      <th>RIDEXAGY</th>\n",
       "      <th>...</th>\n",
       "      <th>SLQ320</th>\n",
       "      <th>SLQ330</th>\n",
       "      <th>SLD013</th>\n",
       "      <th>DR1TWSZ</th>\n",
       "      <th>LBDSATLC</th>\n",
       "      <th>LBDSGTLC</th>\n",
       "      <th>LBDSTBLC</th>\n",
       "      <th>BMXHIP</th>\n",
       "      <th>BMIHIP</th>\n",
       "      <th>LBXNRBC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62161.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62162.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62163.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62164.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62165.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39151</th>\n",
       "      <td>102952.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22:30</td>\n",
       "      <td>07:00</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39152</th>\n",
       "      <td>102953.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>23:00</td>\n",
       "      <td>04:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39153</th>\n",
       "      <td>102954.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00</td>\n",
       "      <td>07:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39154</th>\n",
       "      <td>102955.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39155</th>\n",
       "      <td>102956.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>02:00</td>\n",
       "      <td>09:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39156 rows × 495 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           SEQN  SDDSRVYR  RIDSTATR  RIAGENDR  RIDAGEYR  RIDAGEMN  RIDRETH1  \\\n",
       "0       62161.0       7.0       2.0       1.0      22.0       NaN       3.0   \n",
       "1       62162.0       7.0       2.0       2.0       3.0       NaN       1.0   \n",
       "2       62163.0       7.0       2.0       1.0      14.0       NaN       5.0   \n",
       "3       62164.0       7.0       2.0       2.0      44.0       NaN       3.0   \n",
       "4       62165.0       7.0       2.0       2.0      14.0       NaN       4.0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "39151  102952.0      10.0       2.0       2.0      70.0       NaN       5.0   \n",
       "39152  102953.0      10.0       2.0       1.0      42.0       NaN       1.0   \n",
       "39153  102954.0      10.0       2.0       2.0      41.0       NaN       4.0   \n",
       "39154  102955.0      10.0       2.0       2.0      14.0       NaN       4.0   \n",
       "39155  102956.0      10.0       2.0       1.0      38.0       NaN       3.0   \n",
       "\n",
       "       RIDRETH3  RIDEXMON  RIDEXAGY  ...  SLQ320  SLQ330  SLD013  DR1TWSZ  \\\n",
       "0           3.0       2.0       NaN  ...     NaN     NaN     NaN      NaN   \n",
       "1           1.0       1.0       3.0  ...     NaN     NaN     NaN      NaN   \n",
       "2           6.0       2.0      14.0  ...     NaN     NaN     NaN      NaN   \n",
       "3           3.0       1.0       NaN  ...     NaN     NaN     NaN      NaN   \n",
       "4           4.0       2.0      14.0  ...     NaN     NaN     NaN      NaN   \n",
       "...         ...       ...       ...  ...     ...     ...     ...      ...   \n",
       "39151       6.0       2.0       NaN  ...   22:30   07:00     8.5      4.0   \n",
       "39152       1.0       2.0       NaN  ...   23:00   04:00     5.0      4.0   \n",
       "39153       4.0       1.0       NaN  ...   00:00   07:00     7.0      4.0   \n",
       "39154       4.0       2.0       NaN  ...     NaN     NaN     NaN      1.0   \n",
       "39155       3.0       2.0       NaN  ...   02:00   09:00     7.0      1.0   \n",
       "\n",
       "       LBDSATLC  LBDSGTLC  LBDSTBLC  BMXHIP  BMIHIP  LBXNRBC  \n",
       "0           NaN       NaN       NaN     NaN     NaN      NaN  \n",
       "1           NaN       NaN       NaN     NaN     NaN      NaN  \n",
       "2           NaN       NaN       NaN     NaN     NaN      NaN  \n",
       "3           NaN       NaN       NaN     NaN     NaN      NaN  \n",
       "4           NaN       NaN       NaN     NaN     NaN      NaN  \n",
       "...         ...       ...       ...     ...     ...      ...  \n",
       "39151       0.0       0.0       0.0    87.3     NaN      0.5  \n",
       "39152       0.0       0.0       0.0   112.8     NaN      0.1  \n",
       "39153       0.0       0.0       0.0   102.7     NaN      0.1  \n",
       "39154       0.0       0.0       0.0   128.3     NaN      0.1  \n",
       "39155       0.0       0.0       0.0   110.0     NaN      0.0  \n",
       "\n",
       "[39156 rows x 495 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33cd3276-21d8-4076-a7f2-274376d1bf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (39156, 495)\n",
      "After collapsing *_x/_y: (39156, 481)\n",
      "Dropping 64 DRD item vars.\n",
      "After dropping DRD items: (39156, 417)\n",
      "Dropping 7 weight/design vars.\n",
      "After dropping weights: (39156, 410)\n",
      "Numeric ML matrix: (39156, 405)\n",
      "Dropping 97 high-missing columns.\n",
      "After removing high-missing vars: (39156, 308)\n",
      "Total block-imputed features: 235\n",
      "Imputing block 1: 40 vars...\n",
      "Imputing block 2: 40 vars...\n",
      "Imputing block 3: 40 vars...\n",
      "Imputing block 4: 40 vars...\n",
      "Imputing block 5: 40 vars...\n",
      "Imputing block 6: 35 vars...\n",
      "Saved → nhanes_2011_2018_ml_imputed.feather\n",
      "Shape: (39156, 236)\n",
      "Saved → nhanes_2011_2018_ml_standardized.feather\n",
      "Final standardized shape: (39156, 236)\n",
      "\n",
      "Quick QC:                 SEQN      RIAGENDR      RIDAGEYR      RIDAGEMN      RIDRETH1  \\\n",
      "count   39154.000000  3.915600e+04  3.915600e+04  3.915600e+04  3.915600e+04   \n",
      "mean    82969.579864 -1.587815e-16  4.645493e-17  6.405700e-16  8.129613e-17   \n",
      "std     11844.205773  1.000013e+00  1.000013e+00  1.000013e+00  1.000013e+00   \n",
      "min     62161.000000 -1.013887e+00 -1.298335e+00 -5.393864e+00 -1.667831e+00   \n",
      "25%     73589.250000 -1.013887e+00 -8.956650e-01  1.251259e-02 -8.877835e-01   \n",
      "50%     83378.500000  9.863028e-01 -1.708591e-01  4.413752e-01 -1.077357e-01   \n",
      "75%     93166.750000  9.863028e-01  8.760828e-01  4.413752e-01  6.723122e-01   \n",
      "max    102956.000000  9.863028e-01  1.923025e+00  4.413752e-01  1.452360e+00   \n",
      "\n",
      "           RIDRETH3      DMDEDUC3      DMDEDUC2      DMDMARTL      INDFMIN2  \n",
      "count  3.915600e+04  3.915600e+04  3.915600e+04  3.915600e+04  3.915600e+04  \n",
      "mean   7.548927e-17 -9.799088e-17 -6.162537e-16  2.072326e-16 -2.903433e-18  \n",
      "std    1.000013e+00  1.000013e+00  1.000013e+00  1.000013e+00  1.000013e+00  \n",
      "min   -1.426307e+00 -1.503997e+00 -2.430040e+00 -1.043893e+00 -6.644272e-01  \n",
      "25%   -8.210869e-01 -9.981785e-01 -4.305799e-01 -1.043893e+00 -4.057416e-01  \n",
      "50%   -2.158672e-01  3.506706e-01 -1.839084e-03  3.893508e-01 -2.155520e-01  \n",
      "75%    3.893524e-01  6.639533e-01  5.691500e-01  5.545170e-01  1.763010e-01  \n",
      "max    2.205011e+00  1.518801e+01  5.567800e+00  3.811715e+01  5.673370e+00  \n"
     ]
    }
   ],
   "source": [
    "# warning: this takes for ever to run. just load things in the next cell\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ============================================================\n",
    "# 0. START FROM YOUR FULL STACKED DATAFRAME\n",
    "# ============================================================\n",
    "\n",
    "df_ml = df_all.copy()       # <-- change to your object name\n",
    "df_ml = df_ml.drop_duplicates(subset=[\"SEQN\"])\n",
    "print(\"Initial shape:\", df_ml.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 1. COLLAPSE *_x / *_y DUPLICATE COLUMNS\n",
    "# ============================================================\n",
    "\n",
    "def collapse_suffix_pairs(df, suffixes=(\"_x\", \"_y\")):\n",
    "    cols = df.columns.tolist()\n",
    "    bases = {}\n",
    "\n",
    "    # detect bases\n",
    "    for c in cols:\n",
    "        for suf in suffixes:\n",
    "            if c.endswith(suf):\n",
    "                base = c[:-len(suf)]\n",
    "                bases.setdefault(base, set()).add(c)\n",
    "\n",
    "    # include plain base if present\n",
    "    for base in list(bases.keys()):\n",
    "        if base in df.columns:\n",
    "            bases[base].add(base)\n",
    "\n",
    "    # collapse each base\n",
    "    for base, variants in bases.items():\n",
    "        variants = [v for v in variants if v in df.columns]\n",
    "        ordered = []\n",
    "\n",
    "        if base in df.columns:\n",
    "            ordered.append(base)\n",
    "        for suf in suffixes:\n",
    "            col = base + suf\n",
    "            if col in df.columns:\n",
    "                ordered.append(col)\n",
    "\n",
    "        combined = df[ordered].bfill(axis=1).iloc[:, 0]\n",
    "        df[base] = combined\n",
    "        drop_cols = [c for c in ordered if c != base]\n",
    "        df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_ml = collapse_suffix_pairs(df_ml)\n",
    "print(\"After collapsing *_x/_y:\", df_ml.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 2. DROP ITEM-LEVEL DIET VARIABLES (DRD350*, DRD370*)\n",
    "# ============================================================\n",
    "\n",
    "diet_items = [c for c in df_ml.columns\n",
    "              if c.startswith(\"DRD350\") or c.startswith(\"DRD370\")]\n",
    "\n",
    "print(f\"Dropping {len(diet_items)} DRD item vars.\")\n",
    "df_ml = df_ml.drop(columns=diet_items)\n",
    "print(\"After dropping DRD items:\", df_ml.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 3. DROP SURVEY WEIGHTS & SDMV DESIGN VARS\n",
    "# ============================================================\n",
    "\n",
    "weight_design = [c for c in df_ml.columns\n",
    "                 if c.startswith(\"WT\") or c.startswith(\"SDMV\")]\n",
    "\n",
    "print(f\"Dropping {len(weight_design)} weight/design vars.\")\n",
    "df_ml = df_ml.drop(columns=weight_design)\n",
    "print(\"After dropping weights:\", df_ml.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 4. KEEP ONLY NUMERIC COLUMNS\n",
    "# ============================================================\n",
    "\n",
    "id_cols = [\"SEQN\"]\n",
    "numeric_cols = df_ml.select_dtypes(include=[np.number]).columns.tolist()\n",
    "feature_cols = [c for c in numeric_cols if c not in id_cols]\n",
    "\n",
    "X = df_ml[id_cols + feature_cols].copy()\n",
    "print(\"Numeric ML matrix:\", X.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 5. CLEAN NHANES SPECIAL MISSING CODES\n",
    "# ============================================================\n",
    "\n",
    "missing_codes = {\n",
    "    777: np.nan, 7777: np.nan,\n",
    "    999: np.nan, 9999: np.nan,\n",
    "    77777: np.nan, 99999: np.nan,\n",
    "}\n",
    "\n",
    "X = X.replace(missing_codes)\n",
    "\n",
    "# ============================================================\n",
    "# 6. DROP VARIABLES WITH >95% MISSINGNESS\n",
    "# ============================================================\n",
    "\n",
    "missing_fraction = X.isna().mean()\n",
    "drop_hi_missing = missing_fraction[missing_fraction > 0.95].index.tolist()\n",
    "print(\"Dropping\", len(drop_hi_missing), \"high-missing columns.\")\n",
    "\n",
    "X = X.drop(columns=drop_hi_missing)\n",
    "print(\"After removing high-missing vars:\", X.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 7. BLOCKWISE KNN IMPUTATION (LAPTOP-SAFE)\n",
    "# ============================================================\n",
    "\n",
    "def block_impute(df, block_cols):\n",
    "    \"\"\"Impute only these columns using KNN, return the block.\"\"\"\n",
    "    sub = df[block_cols].copy()\n",
    "    imputer = KNNImputer(n_neighbors=7, weights=\"distance\")\n",
    "    arr = imputer.fit_transform(sub)\n",
    "    return pd.DataFrame(arr, columns=block_cols, index=df.index)\n",
    "\n",
    "# DEFINE BLOCKS (these are safe and optimized for NHANES)\n",
    "block_demo   = [c for c in X.columns if c.startswith((\"RIAGENDR\", \"RIDAGE\", \"RIDRETH\", \"DMDEDUC\", \"DMDMARTL\", \"INDF\"))]\n",
    "block_labs   = [c for c in X.columns if c.startswith((\"LBX\", \"LBD\", \"URX\", \"URD\"))]\n",
    "block_vitals = [c for c in X.columns if c.startswith((\"BPX\", \"BPA\", \"BMX\", \"BMI\"))]\n",
    "block_diet   = [c for c in X.columns if c.startswith((\"DR1T_\", \"DR1KCAL\", \"DR1TPROT\", \"DR1T\"))]\n",
    "block_pa     = [c for c in X.columns if c.startswith((\"PAQ\", \"PAD\"))]\n",
    "block_sleep  = [c for c in X.columns if c.startswith((\"SLQ\", \"SLD\"))]\n",
    "block_mental = [c for c in X.columns if c.startswith((\"DPQ\"))]\n",
    "block_fped   = [c for c in X.columns if c.startswith((\"DR1T_F_\", \"DR1T_V_\", \"DR1T_G_\", \"DR1T_PF_\", \"DR1T_D_\", \"DR1T_OILS\", \"DR1T_SOLID\", \"DR1T_ADD\"))]\n",
    "\n",
    "# union of all blocks\n",
    "all_blocks = block_demo + block_labs + block_vitals + block_diet + block_pa + block_sleep + block_mental + block_fped\n",
    "all_blocks = [c for c in all_blocks if c in X.columns]\n",
    "\n",
    "print(\"Total block-imputed features:\", len(all_blocks))\n",
    "\n",
    "# run imputation blockwise\n",
    "block_results = []\n",
    "batch_size = 40\n",
    "cols = all_blocks\n",
    "\n",
    "for i in range(0, len(cols), batch_size):\n",
    "    subset = cols[i:i+batch_size]\n",
    "    print(f\"Imputing block {i//batch_size+1}: {len(subset)} vars...\")\n",
    "    block_results.append(block_impute(X.set_index(\"SEQN\"), subset))\n",
    "\n",
    "# recombine blocks\n",
    "X_imputed = pd.concat(block_results, axis=1)\n",
    "X_imputed[\"SEQN\"] = X[\"SEQN\"].values\n",
    "X_imputed = X_imputed[[\"SEQN\"] + all_blocks]\n",
    "\n",
    "# SAVE IMPUTATION CHECKPOINT\n",
    "X_imputed.to_feather(\"nhanes_2011_2018_ml_imputed.feather\")\n",
    "print(\"Saved → nhanes_2011_2018_ml_imputed.feather\")\n",
    "print(\"Shape:\", X_imputed.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 8. STANDARDIZE ALL FEATURES\n",
    "# ============================================================\n",
    "\n",
    "feature_cols_final = [c for c in X_imputed.columns if c != \"SEQN\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Z = scaler.fit_transform(X_imputed[feature_cols_final])\n",
    "\n",
    "X_std = pd.DataFrame(Z, columns=feature_cols_final, index=X_imputed.index)\n",
    "X_std.insert(0, \"SEQN\", X_imputed[\"SEQN\"].values)\n",
    "\n",
    "# SAVE STANDARDIZED OUTPUT\n",
    "X_std.to_feather(\"nhanes_2011_2018_ml_standardized.feather\")\n",
    "print(\"Saved → nhanes_2011_2018_ml_standardized.feather\")\n",
    "print(\"Final standardized shape:\", X_std.shape)\n",
    "\n",
    "print(\"\\nQuick QC:\", X_std.iloc[:, :10].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54167ecb-9eae-43d8-9f99-772543900362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load imputed data\n",
    "X_imputed = pd.read_feather(\"nhanes_2011_2018_ml_imputed.feather\")\n",
    "\n",
    "# Load standardized data\n",
    "X_standardized = pd.read_feather(\"nhanes_2011_2018_ml_standardized.feather\")\n",
    "\n",
    "X_imputed.shape, X_standardized.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0edc9c6-0a1e-48a9-85a4-855f60ba1813",
   "metadata": {},
   "source": [
    "Which one should you use?\n",
    "For most ML:\n",
    "\n",
    "Use X_standardized\n",
    "\n",
    "Is standardized → great for PCA, clustering, graphical lasso, autoencoders, gradient boosting.\n",
    "\n",
    "For single-variable inspection or sanity checking:\n",
    "\n",
    "Use X_imputed\n",
    "\n",
    "Not standardized → raw-ish values, but missing values imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0425d943-ba03-469a-bf1b-8dad27ef22c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_standardized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mX_standardized\u001b[49m.columns.tolist()\n",
      "\u001b[31mNameError\u001b[39m: name 'X_standardized' is not defined"
     ]
    }
   ],
   "source": [
    "X_standardized.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c13da2-9d15-4b77-83dc-624e04374b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standardized[[\"SEQN\"]].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
