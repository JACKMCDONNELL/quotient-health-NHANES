{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19780287-c46f-468d-ab02-bf571b7efb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading DEMO (DEMO_I.xpt)...\n",
      "  Loaded DEMO: (9971, 47)\n",
      "Downloading HDL (HDL_I.xpt)...\n",
      "  Loaded HDL: (8021, 3)\n",
      "Downloading TCHOL (TCHOL_I.xpt)...\n",
      "  Loaded TCHOL: (8021, 3)\n",
      "Downloading TRIGLY (TRIGLY_I.xpt)...\n",
      "  Loaded TRIGLY: (3191, 6)\n",
      "Downloading GLU (GLU_I.xpt)...\n",
      "  Loaded GLU: (3191, 4)\n",
      "Downloading INS (INS_I.xpt)...\n",
      "  Loaded INS: (3191, 7)\n",
      "Downloading DPQ (DPQ_I.xpt)...\n",
      "  Loaded DPQ: (5735, 11)\n",
      "Downloading SLQ (SLQ_I.xpt)...\n",
      "  Loaded SLQ: (6327, 8)\n",
      "Downloading DR1TOT (DR1TOT_I.xpt)...\n",
      "  Loaded DR1TOT: (9544, 168)\n",
      "Downloading DR1IFF (DR1IFF_I.xpt)...\n",
      "  Loaded DR1IFF: (121481, 84)\n",
      "Downloading PAQ (PAQ_I.xpt)...\n",
      "  Loaded PAQ: (9255, 94)\n",
      "Downloading BPX (BPX_I.xpt)...\n",
      "  Loaded BPX: (9544, 21)\n",
      "Downloading BIOPRO (BIOPRO_I.xpt)...\n",
      "  Loaded BIOPRO: (6744, 38)\n",
      "Downloading ALB_CR (ALB_CR_I.xpt)...\n",
      "  Loaded ALB_CR: (8608, 8)\n",
      "\n",
      "After merging person-level NHANES files: (9971, 406)\n",
      "FPED shape: (9544, 51)\n",
      "FPED first few columns: ['SEQN', 'RIAGENDR', 'RIDAGEYR', 'RIDRETH3', 'SDMVPSU', 'SDMVSTRA', 'INDFMIN2', 'INDFMPIR', 'WTDRD1', 'WTDR2D', 'DR1DRSTZ', 'DRABF', 'DRDINT', 'DR1TNUMF', 'DR1T_F_CITMLB', 'DR1T_F_OTHER', 'DR1T_F_JUICE', 'DR1T_F_TOTAL', 'DR1T_V_DRKGR', 'DR1T_V_REDOR_TOMATO']\n",
      "After merging FPED: (9971, 456)\n",
      "Duplicate variable bases found: {'DRABF', 'INDFMPIR', 'RIAGENDR', 'WTSAF2YR', 'SDMVPSU', 'INDFMIN2', 'DR1DRSTZ', 'RIDRETH3', 'DRDINT', 'WTDRD1', 'DR1TNUMF', 'WTDR2D', 'RIDAGEYR', 'SDMVSTRA'}\n",
      "✓ All *_x / *_y duplicates cleaned.\n",
      "Remaining *_x / *_y columns: []\n",
      "Found WTSAF2YR variants: ['WTSAF2YR', 'WTSAF2YR']\n",
      "✓ Cleaned. Remaining WTSAF2YR columns: []\n",
      "\n",
      "Feature table shape: (9971, 455)\n",
      "\n",
      "✓ rPDQS columns present? True True\n",
      "      SEQN  rpdqs_total  rpdqs_normalized\n",
      "0  83732.0         21.0         37.500000\n",
      "1  83733.0          9.0         16.071429\n",
      "2  83734.0         25.0         44.642857\n",
      "3  83735.0         28.0         50.000000\n",
      "4  83736.0         27.0         48.214286\n",
      "\n",
      "Longevity variable matrix shape: (9971, 21)\n",
      "      SEQN  ogtt_norm  apob_norm  vo2max_norm  crp_norm  bmi_norm  \\\n",
      "0  83732.0        NaN        NaN          NaN       NaN       NaN   \n",
      "1  83733.0        NaN    -8.6125          NaN       NaN       NaN   \n",
      "2  83734.0        NaN    -1.6000          NaN       NaN       NaN   \n",
      "3  83735.0        NaN        NaN          NaN       NaN       NaN   \n",
      "4  83736.0        NaN    29.0750          NaN       NaN       NaN   \n",
      "\n",
      "   pack_years_norm  moca_norm  mvpa_norm  cac_norm  ...  phq9_norm  alt_norm  \\\n",
      "0              NaN        NaN        NaN       NaN  ...  96.296296       NaN   \n",
      "1              NaN        NaN        NaN       NaN  ...  92.592593       NaN   \n",
      "2              NaN        NaN        NaN       NaN  ...  96.296296       NaN   \n",
      "3              NaN        NaN        NaN       NaN  ...  51.851852       NaN   \n",
      "4              NaN        NaN        NaN       NaN  ...  70.370370       NaN   \n",
      "\n",
      "    egfr_norm  bmd_norm  truage_norm  shdl_norm  rem_norm  grip_norm  \\\n",
      "0   73.132726       NaN          NaN        NaN       NaN        NaN   \n",
      "1   49.757429       NaN          NaN        NaN       NaN        NaN   \n",
      "2   14.483540       NaN          NaN        NaN       NaN        NaN   \n",
      "3   17.231586       NaN          NaN        NaN       NaN        NaN   \n",
      "4  103.488549       NaN          NaN        NaN       NaN        NaN   \n",
      "\n",
      "   swls_norm  diet_norm  \n",
      "0        NaN  37.500000  \n",
      "1        NaN  16.071429  \n",
      "2        NaN  44.642857  \n",
      "3        NaN  50.000000  \n",
      "4        NaN  48.214286  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tempfile\n",
    "import os\n",
    "import pyreadstat\n",
    "\n",
    "# ============================================================\n",
    "# 0. Helper: Download any NHANES .xpt file\n",
    "# ============================================================\n",
    "\n",
    "def load_nhanes_xpt(file, year=\"2015\"):\n",
    "    \"\"\"\n",
    "    file: e.g. 'DEMO_I.xpt'\n",
    "    year: '2015'  (for 2015–2016 cycle)\n",
    "    \"\"\"\n",
    "    url = f\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/{year}/DataFiles/{file}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/120.0 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "    r = requests.get(url, headers=headers)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    # If server returned HTML (error), fail clearly\n",
    "    if b\"<html\" in r.content[:200].lower():\n",
    "        preview = r.content[:500].decode(errors=\"ignore\")\n",
    "        raise ValueError(f\"HTML returned instead of XPT:\\n{url}\\n\\nPreview:\\n{preview}\")\n",
    "\n",
    "    # write to temp file\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".xpt\", delete=False) as tmp:\n",
    "        tmp.write(r.content)\n",
    "        tmp_path = tmp.name\n",
    "\n",
    "    try:\n",
    "        df, meta = pyreadstat.read_xport(tmp_path)\n",
    "    finally:\n",
    "        os.remove(tmp_path)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. Download + merge NHANES 2015–2016 person-level files\n",
    "# ============================================================\n",
    "\n",
    "nhanes_files = {\n",
    "    \"DEMO\":      \"DEMO_I.xpt\",\n",
    "    \"HDL\":       \"HDL_I.xpt\",\n",
    "    \"TCHOL\":     \"TCHOL_I.xpt\",\n",
    "    \"TRIGLY\":    \"TRIGLY_I.xpt\",\n",
    "    \"GLU\":       \"GLU_I.xpt\",\n",
    "    \"INS\":       \"INS_I.xpt\",\n",
    "    \"DPQ\":       \"DPQ_I.xpt\",\n",
    "    \"SLQ\":       \"SLQ_I.xpt\",\n",
    "    \"DR1TOT\":    \"DR1TOT_I.xpt\",   # day 1 total intake\n",
    "    \"DR1IFF\":    \"DR1IFF_I.xpt\",   # food items (we won't use for FPED-based rPDQS)\n",
    "    \"PAQ\":       \"PAQ_I.xpt\",\n",
    "    \"BPX\":       \"BPX_I.xpt\",\n",
    "    \"BIOPRO\":    \"BIOPRO_I.xpt\",\n",
    "    \"ALB_CR\":    \"ALB_CR_I.xpt\"\n",
    "}\n",
    "\n",
    "all_dfs = {}\n",
    "for name, fname in nhanes_files.items():\n",
    "    print(f\"Downloading {name} ({fname})...\")\n",
    "    df_tmp = load_nhanes_xpt(fname, \"2015\")\n",
    "    all_dfs[name] = df_tmp\n",
    "    print(f\"  Loaded {name}: {df_tmp.shape}\")\n",
    "\n",
    "# Start from DEMO as person-level base\n",
    "df = all_dfs[\"DEMO\"].copy()\n",
    "\n",
    "# Merge all other files EXCEPT DR1IFF (we don't want item-level explosion)\n",
    "for name, d in all_dfs.items():\n",
    "    if name in [\"DEMO\", \"DR1IFF\"]:\n",
    "        continue\n",
    "    df = df.merge(d, on=\"SEQN\", how=\"left\")\n",
    "\n",
    "print(\"\\nAfter merging person-level NHANES files:\", df.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 2. Load FPED DR1TOT day-1 file and merge\n",
    "#    You already have: fped_dr1tot_1516.sas7bdat in working dir\n",
    "# ============================================================\n",
    "\n",
    "fped, meta_fped = pyreadstat.read_sas7bdat(\"fped_dr1tot_1516.sas7bdat\")\n",
    "fped = fped.copy()\n",
    "\n",
    "print(\"FPED shape:\", fped.shape)\n",
    "print(\"FPED first few columns:\", list(fped.columns[:20]))\n",
    "\n",
    "# Merge FPED (per-person food group equivalents for day 1)\n",
    "df = df.merge(fped, on=\"SEQN\", how=\"left\")\n",
    "print(\"After merging FPED:\", df.shape)\n",
    "\n",
    "# ============================================================\n",
    "# CLEAN ALL *_x / *_y DUPLICATES ACROSS THE ENTIRE DATAFRAME\n",
    "# ============================================================\n",
    "df = df.copy()\n",
    "\n",
    "all_cols = df.columns\n",
    "base_vars = set()\n",
    "\n",
    "# Identify every base variable that has *_x or *_y versions.\n",
    "for c in all_cols:\n",
    "    if c.endswith(\"_x\") or c.endswith(\"_y\"):\n",
    "        base_vars.add(c[:-2])\n",
    "\n",
    "print(\"Duplicate variable bases found:\", base_vars)\n",
    "\n",
    "for base in base_vars:\n",
    "    col_x = base + \"_x\"\n",
    "    col_y = base + \"_y\"\n",
    "\n",
    "    # Case 1 — both exist → keep _x, drop _y, rename _x → base\n",
    "    if col_x in df.columns and col_y in df.columns:\n",
    "        df.drop(columns=[col_y], inplace=True)\n",
    "        df.rename(columns={col_x: base}, inplace=True)\n",
    "\n",
    "    # Case 2 — only _x exists → rename to base if base not already in df\n",
    "    elif col_x in df.columns and base not in df.columns:\n",
    "        df.rename(columns={col_x: base}, inplace=True)\n",
    "\n",
    "    # Case 3 — only _y exists → rename to base if base not already in df\n",
    "    elif col_y in df.columns and base not in df.columns:\n",
    "        df.rename(columns={col_y: base}, inplace=True)\n",
    "\n",
    "print(\"✓ All *_x / *_y duplicates cleaned.\")\n",
    "\n",
    "# Verify no duplicates remain\n",
    "print(\"Remaining *_x / *_y columns:\",\n",
    "      [c for c in df.columns if c.endswith('_x') or c.endswith('_y')])\n",
    "\n",
    "# Now safe to make master copy\n",
    "df_master = df.copy()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# FIX DUPLICATE NHANES DEMOGRAPHIC COLUMNS\n",
    "# Keep the \"_x\" versions and drop the \"_y\" duplicates\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "demo_vars = [\n",
    "    \"RIAGENDR\", \"RIDAGEYR\", \"RIDRETH3\",\n",
    "    \"SDMVPSU\", \"SDMVSTRA\",\n",
    "    \"INDFMIN2\", \"INDFMPIR\",\n",
    "    \"WTDRD1\", \"WTDR2D\", \"DR1DRSTZ\", \"DRABF\", \"DRDINT\", \"DR1TNUMF\"\n",
    "]\n",
    "\n",
    "# Step 1: rename all _x versions back to their base name\n",
    "rename_map = {}\n",
    "for var in demo_vars:\n",
    "    old = var + \"_x\"\n",
    "    if old in df_master.columns:\n",
    "        rename_map[old] = var\n",
    "\n",
    "df_master = df_master.rename(columns=rename_map)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# FIX DUPLICATE WEIGHT VARIABLES *INSIDE df_master*\n",
    "# ----------------------------------------------------\n",
    "\n",
    "wtsaf_cols = [c for c in df_master.columns if c.startswith(\"WTSAF2YR\")]\n",
    "\n",
    "print(\"Found WTSAF2YR variants:\", wtsaf_cols)\n",
    "\n",
    "if len(wtsaf_cols) > 1:\n",
    "    # Combine into a single variable using first non-null value\n",
    "    df_master[\"WTSAF2YR\"] = df_master[wtsaf_cols].bfill(axis=1).iloc[:, 0]\n",
    "\n",
    "    # Drop all the original variants\n",
    "    df_master.drop(columns=wtsaf_cols, inplace=True)\n",
    "\n",
    "    print(\"✓ Cleaned. Remaining WTSAF2YR columns:\",\n",
    "          [c for c in df_master.columns if \"WTSAF2YR\" in c])\n",
    "else:\n",
    "    print(\"No duplicates found — nothing to clean.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. Feature Engineering (labs, BP, eGFR, sleep, PA, PHQ)\n",
    "# ============================================================\n",
    "\n",
    "df = df_master.copy()  # work on a fresh copy\n",
    "\n",
    "# -----------------------------\n",
    "# 3.1 Basic demographics\n",
    "# -----------------------------\n",
    "df[\"sex\"] = df[\"RIAGENDR\"]               # 1=Male, 2=Female\n",
    "df[\"race_ethnicity\"] = df[\"RIDRETH3\"]    # consistent with Longevity v1.1\n",
    "df[\"age\"] = df[\"RIDAGEYR\"]               # age in years\n",
    "df[\"poverty_income_ratio\"] = df[\"INDFMIN2\"]\n",
    "\n",
    "# -----------------------------\n",
    "# 3.2 Rename biochemical variables\n",
    "# -----------------------------\n",
    "rename_map = {\n",
    "    \"LBXGLU\": \"fasting_glucose\",\n",
    "    \"LBXIN\": \"fasting_insulin\",\n",
    "    \"LBDHDD\": \"hdl_cholesterol\",   # HDL_I\n",
    "    \"LBDHDL\": \"hdl_cholesterol\",   # alt name (not needed here but safe)\n",
    "    \"LBXTC\": \"total_cholesterol\",\n",
    "    \"LBXTR\": \"triglycerides\",\n",
    "    \"LBXSCR\": \"serum_creatinine\"\n",
    "}\n",
    "\n",
    "df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns},\n",
    "          inplace=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 3.3 LDL (Friedewald) + ApoB est\n",
    "# -----------------------------\n",
    "def friedewald_ldl(row):\n",
    "    tg = row[\"triglycerides\"]\n",
    "    if pd.isna(tg) or tg >= 400:\n",
    "        return np.nan\n",
    "    return row[\"total_cholesterol\"] - row[\"hdl_cholesterol\"] - tg / 5\n",
    "\n",
    "if {\"total_cholesterol\", \"hdl_cholesterol\", \"triglycerides\"}.issubset(df.columns):\n",
    "    df[\"ldl_cholesterol\"] = df.apply(friedewald_ldl, axis=1)\n",
    "    df[\"apob_est\"] = 0.65 * df[\"ldl_cholesterol\"] + 0.1 * df[\"triglycerides\"]\n",
    "else:\n",
    "    df[\"ldl_cholesterol\"] = np.nan\n",
    "    df[\"apob_est\"] = np.nan\n",
    "\n",
    "# -----------------------------\n",
    "# 3.4 HOMA-IR\n",
    "# -----------------------------\n",
    "if {\"fasting_glucose\", \"fasting_insulin\"}.issubset(df.columns):\n",
    "    df[\"homa_ir\"] = (df[\"fasting_insulin\"] * df[\"fasting_glucose\"]) / 405\n",
    "else:\n",
    "    df[\"homa_ir\"] = np.nan\n",
    "\n",
    "# -----------------------------\n",
    "# 3.5 Blood pressure aggregates\n",
    "# -----------------------------\n",
    "sbp_cols = [c for c in df.columns if c.startswith(\"BPXSY\")]\n",
    "dbp_cols = [c for c in df.columns if c.startswith(\"BPXDI\")]\n",
    "\n",
    "if sbp_cols:\n",
    "    df[\"sbp\"] = df[sbp_cols].mean(axis=1)\n",
    "if dbp_cols:\n",
    "    df[\"dbp\"] = df[dbp_cols].mean(axis=1)\n",
    "\n",
    "if {\"sbp\", \"dbp\"}.issubset(df.columns):\n",
    "    df[\"pulse_pressure\"] = df[\"sbp\"] - df[\"dbp\"]\n",
    "else:\n",
    "    df[\"pulse_pressure\"] = np.nan\n",
    "\n",
    "# -----------------------------\n",
    "# 3.6 eGFR — CKD-EPI 2021 (race-free)\n",
    "# -----------------------------\n",
    "if {\"serum_creatinine\", \"sex\", \"age\"}.issubset(df.columns):\n",
    "    scr = df[\"serum_creatinine\"]\n",
    "    sex = df[\"sex\"]\n",
    "    age = df[\"age\"]\n",
    "\n",
    "    k = np.where(sex == 2, 0.7, 0.9)\n",
    "    alpha = np.where(sex == 2, -0.241, -0.302)\n",
    "\n",
    "    min_part = np.minimum(scr / k, 1) ** alpha\n",
    "    max_part = np.maximum(scr / k, 1) ** -1.2\n",
    "\n",
    "    df[\"egfr\"] = 142 * min_part * max_part * (0.9938 ** age)\n",
    "else:\n",
    "    df[\"egfr\"] = np.nan\n",
    "\n",
    "# -----------------------------\n",
    "# 3.7 Sleep metrics (SLQ030)\n",
    "# -----------------------------\n",
    "if \"SLQ030\" in df.columns:\n",
    "    df[\"sleep_hours\"] = df[\"SLQ030\"]\n",
    "\n",
    "    def sleep_score(x):\n",
    "        if pd.isna(x):\n",
    "            return np.nan\n",
    "        if 7 <= x <= 9:\n",
    "            return 100\n",
    "        if 6 <= x < 7 or 9 < x <= 10:\n",
    "            return 80\n",
    "        return 50\n",
    "\n",
    "    df[\"sleep_score\"] = df[\"sleep_hours\"].apply(sleep_score)\n",
    "else:\n",
    "    df[\"sleep_hours\"] = np.nan\n",
    "    df[\"sleep_score\"] = np.nan\n",
    "\n",
    "# -----------------------------\n",
    "# 3.8 Physical Activity (leisure MVPA)\n",
    "# -----------------------------\n",
    "if {\"PAD615\", \"PAD630\"}.issubset(df.columns):\n",
    "    vig_min = df[\"PAD615\"] * df[\"PAD630\"]\n",
    "else:\n",
    "    vig_min = np.nan\n",
    "\n",
    "if {\"PAD645\", \"PAD660\"}.issubset(df.columns):\n",
    "    mod_min = df[\"PAD645\"] * df[\"PAD660\"]\n",
    "else:\n",
    "    mod_min = np.nan\n",
    "\n",
    "if not (isinstance(vig_min, float) and isinstance(mod_min, float)):\n",
    "    df[\"mvpa_min_week\"] = vig_min * 2 + mod_min\n",
    "else:\n",
    "    df[\"mvpa_min_week\"] = np.nan\n",
    "\n",
    "# -----------------------------\n",
    "# 3.9 PHQ-9 total\n",
    "# -----------------------------\n",
    "phq_cols = [c for c in df.columns if c.startswith(\"DPQ0\")]\n",
    "if phq_cols:\n",
    "    df[\"phq9_total\"] = df[phq_cols].sum(axis=1)\n",
    "else:\n",
    "    df[\"phq9_total\"] = np.nan\n",
    "\n",
    "# -----------------------------\n",
    "# 3.10 Clean common NHANES codes\n",
    "# -----------------------------\n",
    "df.replace({7777: np.nan, 9999: np.nan, 99999: np.nan, 999999: np.nan},\n",
    "           inplace=True)\n",
    "\n",
    "# At this point df is your main feature-engineered table\n",
    "df_features = df.copy()\n",
    "print(\"\\nFeature table shape:\", df_features.shape)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. rPDQS-style diet score from FPED day 1\n",
    "#    using DR1T_* variables in FPED_DR1TOT_1516\n",
    "# ============================================================\n",
    "\n",
    "df = df_features.copy()\n",
    "\n",
    "# If DR1DRSTZ (recall status) exists, restrict to reliable day 1\n",
    "if \"DR1DRSTZ\" in df.columns:\n",
    "    bad_mask = df[\"DR1DRSTZ\"] != 1\n",
    "else:\n",
    "    bad_mask = pd.Series(False, index=df.index)\n",
    "\n",
    "# List of FPED variables we plan to use\n",
    "fped_vars_needed = [\n",
    "    \"DR1T_F_CITMLB\", \"DR1T_F_OTHER\",\n",
    "    \"DR1T_V_DRKGR\", \"DR1T_V_OTHER\",\n",
    "    \"DR1T_V_REDOR_TOTAL\", \"DR1T_V_STARCHY_TOTAL\", \"DR1T_V_LEGUMES\",\n",
    "    \"DR1T_G_WHOLE\", \"DR1T_G_REFINED\",\n",
    "    \"DR1T_PF_MEAT\", \"DR1T_PF_CUREDMEAT\",\n",
    "    \"DR1T_PF_SEAFD_HI\", \"DR1T_PF_SEAFD_LOW\",\n",
    "    \"DR1T_PF_NUTSDS\",\n",
    "    \"DR1T_D_MILK\", \"DR1T_D_YOGURT\",\n",
    "    \"DR1T_A_DRINKS\", \"DR1T_SOLID_FATS\"\n",
    "]\n",
    "\n",
    "# Guarantee these columns exist (if missing, create with NaN)\n",
    "for col in fped_vars_needed:\n",
    "    if col not in df.columns:\n",
    "        df[col] = np.nan\n",
    "\n",
    "# Set FPED vars to NaN when recall is unreliable\n",
    "if \"DR1DRSTZ\" in df.columns:\n",
    "    df.loc[bad_mask, fped_vars_needed] = np.nan\n",
    "\n",
    "# --- Construct approximate rPDQS food groups (servings/day) ---\n",
    "df[\"dark_green_veg\"]        = df[\"DR1T_V_DRKGR\"]\n",
    "df[\"other_veg\"]             = (\n",
    "    df[\"DR1T_V_OTHER\"]\n",
    "    + df[\"DR1T_V_REDOR_TOTAL\"]\n",
    "    + df[\"DR1T_V_STARCHY_TOTAL\"]\n",
    "    - df[\"DR1T_V_LEGUMES\"].fillna(0)\n",
    ")\n",
    "df[\"citrus_melons_berries\"] = df[\"DR1T_F_CITMLB\"]\n",
    "df[\"other_fruit\"]           = df[\"DR1T_F_OTHER\"]\n",
    "df[\"legumes\"]               = df[\"DR1T_V_LEGUMES\"]                   # could add PF_LEGUMES if present\n",
    "df[\"whole_grains\"]          = df[\"DR1T_G_WHOLE\"]\n",
    "df[\"nuts_seeds\"]            = df[\"DR1T_PF_NUTSDS\"]\n",
    "df[\"low_fat_dairy\"]         = df[\"DR1T_D_MILK\"] + df[\"DR1T_D_YOGURT\"]\n",
    "df[\"fish\"]                  = df[\"DR1T_PF_SEAFD_HI\"] + df[\"DR1T_PF_SEAFD_LOW\"]\n",
    "\n",
    "df[\"red_meat\"]              = df[\"DR1T_PF_MEAT\"]\n",
    "df[\"processed_meat\"]        = df[\"DR1T_PF_CUREDMEAT\"]\n",
    "df[\"refined_grains\"]        = df[\"DR1T_G_REFINED\"]\n",
    "df[\"ssb\"]                   = df[\"DR1T_A_DRINKS\"]\n",
    "df[\"fried_foods\"]           = df[\"DR1T_SOLID_FATS\"]   # crude proxy\n",
    "\n",
    "healthy_groups = [\n",
    "    \"dark_green_veg\",\"other_veg\",\"citrus_melons_berries\",\"other_fruit\",\n",
    "    \"legumes\",\"whole_grains\",\"nuts_seeds\",\"low_fat_dairy\",\"fish\"\n",
    "]\n",
    "unhealthy_groups = [\n",
    "    \"red_meat\",\"processed_meat\",\"refined_grains\",\"ssb\",\"fried_foods\"\n",
    "]\n",
    "\n",
    "servings = df[[\"SEQN\"] + healthy_groups + unhealthy_groups].set_index(\"SEQN\")\n",
    "\n",
    "def pos_score(s):\n",
    "    \"\"\"Higher intake = better (for healthy groups).\"\"\"\n",
    "    s = s.fillna(0)\n",
    "    if s.nunique() <= 1 or s.notna().sum() < 5:\n",
    "        # If basically no variation, just give everyone 0\n",
    "        return pd.Series(0.0, index=s.index)\n",
    "    ranked = s.rank(method=\"first\")\n",
    "    return pd.qcut(ranked, 5, labels=[0,1,2,3,4], duplicates=\"drop\").astype(float)\n",
    "\n",
    "def neg_score(s):\n",
    "    \"\"\"Lower intake = better (for unhealthy groups).\"\"\"\n",
    "    s = s.fillna(0)\n",
    "    if s.nunique() <= 1 or s.notna().sum() < 5:\n",
    "        # If no variation, everyone gets middle-ish score (2) or 0; here choose 0\n",
    "        return pd.Series(0.0, index=s.index)\n",
    "    ranked = s.rank(method=\"first\")\n",
    "    return pd.qcut(ranked, 5, labels=[4,3,2,1,0], duplicates=\"drop\").astype(float)\n",
    "\n",
    "# Apply scoring\n",
    "for g in healthy_groups:\n",
    "    servings[g + \"_score\"] = pos_score(servings[g])\n",
    "\n",
    "for g in unhealthy_groups:\n",
    "    servings[g + \"_score\"] = neg_score(servings[g])\n",
    "\n",
    "score_cols = [g + \"_score\" for g in healthy_groups + unhealthy_groups]\n",
    "\n",
    "servings[\"rpdqs_total\"] = servings[score_cols].sum(axis=1)\n",
    "\n",
    "# There are 14 groups * max 4 points = 56\n",
    "servings[\"rpdqs_normalized\"] = (servings[\"rpdqs_total\"] / 56.0) * 100\n",
    "\n",
    "# Merge back into main df\n",
    "df = df.merge(\n",
    "    servings[[\"rpdqs_total\",\"rpdqs_normalized\"]],\n",
    "    left_on=\"SEQN\", right_index=True, how=\"left\"\n",
    ")\n",
    "\n",
    "# This is now your fully-featured dataset\n",
    "df_final = df.copy()\n",
    "print(\"\\n✓ rPDQS columns present?\",\n",
    "      \"rpdqs_total\" in df_final.columns,\n",
    "      \"rpdqs_normalized\" in df_final.columns)\n",
    "print(df_final[[\"SEQN\",\"rpdqs_total\",\"rpdqs_normalized\"]].head())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. Longevity Score v1.1: normalize all inputs (0–100)\n",
    "# ============================================================\n",
    "\n",
    "df = df_final.copy()\n",
    "\n",
    "# ---- BMI ----\n",
    "if {\"BMXWT\", \"BMXHT\"}.issubset(df.columns):\n",
    "    df[\"bmi\"] = df[\"BMXWT\"] / (df[\"BMXHT\"] / 100)**2\n",
    "else:\n",
    "    df[\"bmi\"] = np.nan\n",
    "\n",
    "def normalize_positive(x, low, high):\n",
    "    return ((x - low) / (high - low)) * 100\n",
    "\n",
    "def normalize_negative(x, low, high):\n",
    "    return ((high - x) / (high - low)) * 100\n",
    "\n",
    "# VO2max & OGTT not in NHANES\n",
    "df[\"vo2max_raw\"] = np.nan\n",
    "df[\"vo2max_norm\"] = np.nan\n",
    "df[\"ogtt_raw\"] = np.nan\n",
    "df[\"ogtt_norm\"] = np.nan\n",
    "\n",
    "# ApoB\n",
    "if \"apob_est\" in df.columns:\n",
    "    df[\"apob_norm\"] = normalize_negative(df[\"apob_est\"], low=40, high=120)\n",
    "else:\n",
    "    df[\"apob_norm\"] = np.nan\n",
    "\n",
    "# CRP (LBXCRP)\n",
    "if \"LBXCRP\" in df.columns:\n",
    "    df[\"crp_norm\"] = normalize_negative(df[\"LBXCRP\"], low=0.1, high=10)\n",
    "else:\n",
    "    df[\"crp_norm\"] = np.nan\n",
    "\n",
    "# BMI\n",
    "df[\"bmi_norm\"] = normalize_negative(df[\"bmi\"], low=18.5, high=35)\n",
    "\n",
    "# Smoking pack-years (very crude proxy)\n",
    "if {\"SMD630\", \"SMD641\"}.issubset(df.columns):\n",
    "    df[\"cigs_per_day\"] = df[\"SMD630\"]\n",
    "    df[\"years_smoked\"] = df[\"SMD641\"]\n",
    "    df[\"pack_years\"] = (df[\"cigs_per_day\"] / 20) * df[\"years_smoked\"]\n",
    "    df[\"pack_years_norm\"] = normalize_negative(df[\"pack_years\"], low=0, high=50)\n",
    "else:\n",
    "    df[\"pack_years_norm\"] = np.nan\n",
    "\n",
    "# MoCA not in NHANES\n",
    "df[\"moca_norm\"] = np.nan\n",
    "\n",
    "# MVPA\n",
    "if \"mvpa_min_week\" in df.columns:\n",
    "    df[\"mvpa_norm\"] = normalize_positive(df[\"mvpa_min_week\"], low=0, high=300)\n",
    "else:\n",
    "    df[\"mvpa_norm\"] = np.nan\n",
    "\n",
    "# CAC / HRV not in NHANES\n",
    "df[\"cac_norm\"] = np.nan\n",
    "df[\"hrv_norm\"] = np.nan\n",
    "\n",
    "# PHQ-9\n",
    "df[\"phq9_norm\"] = normalize_negative(df[\"phq9_total\"], low=0, high=27)\n",
    "\n",
    "# ALT (LBXSGPT)\n",
    "if \"LBXSGPT\" in df.columns:\n",
    "    df[\"alt_norm\"] = normalize_negative(df[\"LBXSGPT\"], low=8, high=50)\n",
    "else:\n",
    "    df[\"alt_norm\"] = np.nan\n",
    "\n",
    "# eGFR\n",
    "if \"egfr\" in df.columns:\n",
    "    df[\"egfr_norm\"] = normalize_positive(df[\"egfr\"], low=60, high=110)\n",
    "else:\n",
    "    df[\"egfr_norm\"] = np.nan\n",
    "\n",
    "# BMD, TruAge, shdl, REM, SWLS not available\n",
    "df[\"bmd_norm\"] = np.nan\n",
    "df[\"truage_norm\"] = np.nan\n",
    "df[\"shdl_norm\"] = np.nan\n",
    "df[\"rem_norm\"] = np.nan\n",
    "df[\"swls_norm\"] = np.nan\n",
    "\n",
    "# Grip strength (if MGDC* present)\n",
    "grip_vars = [c for c in df.columns if \"MGDC\" in c]\n",
    "if grip_vars:\n",
    "    df[\"grip_strength\"] = df[grip_vars].max(axis=1)\n",
    "    df[\"grip_norm\"] = normalize_positive(df[\"grip_strength\"], low=10, high=60)\n",
    "else:\n",
    "    df[\"grip_norm\"] = np.nan\n",
    "\n",
    "# Diet quality\n",
    "df[\"diet_norm\"] = df[\"rpdqs_normalized\"]\n",
    "\n",
    "# Collect Longevity Score 1.1 variables\n",
    "longevity_inputs = [\n",
    "    \"ogtt_norm\",\"apob_norm\",\"vo2max_norm\",\"crp_norm\",\"bmi_norm\",\n",
    "    \"pack_years_norm\",\"moca_norm\",\"mvpa_norm\",\"cac_norm\",\"hrv_norm\",\n",
    "    \"phq9_norm\",\"alt_norm\",\"egfr_norm\",\"bmd_norm\",\"truage_norm\",\n",
    "    \"shdl_norm\",\"rem_norm\",\"grip_norm\",\"swls_norm\",\"diet_norm\"\n",
    "]\n",
    "\n",
    "df_longevity = df[[\"SEQN\"] + longevity_inputs].copy()\n",
    "\n",
    "print(\"\\nLongevity variable matrix shape:\", df_longevity.shape)\n",
    "print(df_longevity.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8f7b1b6-7a17-47ed-ae4f-ab1efc049c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC function\n",
    "def nhanes_qc(df_master, fped):\n",
    "    print(\"===============================================\")\n",
    "    print(\"        NHANES MERGE QUALITY CHECK (QC)\")\n",
    "    print(\"===============================================\")\n",
    "\n",
    "    # 1. Shape check\n",
    "    print(\"\\n[1] Dataset shape:\")\n",
    "    print(\"    df_master.shape =\", df_master.shape)\n",
    "    if df_master.shape[0] in [9969, 9970, 9971]:\n",
    "        print(\"    ✓ PASS — correct number of rows for 2015–2016 DEMO\")\n",
    "    else:\n",
    "        print(\"    ✗ FAIL — unexpected row count\")\n",
    "\n",
    "    # 2. Unique SEQN\n",
    "    print(\"\\n[2] Unique SEQN check:\")\n",
    "    uniq = df_master[\"SEQN\"].is_unique\n",
    "    print(\"    SEQN unique? →\", uniq)\n",
    "    print(\"    ✓ PASS\" if uniq else \"    ✗ FAIL — duplicates present\")\n",
    "\n",
    "    # 3. Check for lingering _x/_y duplicates\n",
    "    dup_cols = [c for c in df_master.columns if \"_x\" in c or \"_y\" in c]\n",
    "    print(\"\\n[3] Duplicate merge columns (_x/_y):\")\n",
    "    print(\"    Found:\", dup_cols)\n",
    "    if len(dup_cols) == 0:\n",
    "        print(\"    ✓ PASS — all merge duplicates cleaned\")\n",
    "    else:\n",
    "        print(\"    ✗ FAIL — merge duplicates remain\")\n",
    "\n",
    "    # 4. Verify FPED variables present\n",
    "    fped_cols = df_master.filter(regex=\"^DR1T_\").columns.tolist()\n",
    "    print(\"\\n[4] FPED variable check:\")\n",
    "    print(\"    Number of DR1T_* columns:\", len(fped_cols))\n",
    "    if len(fped_cols) > 50:\n",
    "        print(\"    ✓ PASS — FPED merged correctly\")\n",
    "    else:\n",
    "        print(\"    ✗ FAIL — FPED variables missing\")\n",
    "\n",
    "    # 5. DR1DRSTZ for SEQN 93700\n",
    "    print(\"\\n[5] DR1DRSTZ for SEQN 93700 (expected = 2.0):\")\n",
    "    val = df_master.loc[df_master[\"SEQN\"] == 93700, \"DR1DRSTZ\"]\n",
    "    print(\"    Value:\", list(val))\n",
    "    if len(val) == 1 and float(val.iloc[0]) == 2.0:\n",
    "        print(\"    ✓ PASS — correct DR1DRSTZ merge for 93700\")\n",
    "    else:\n",
    "        print(\"    ✗ FAIL — unexpected DR1DRSTZ value for 93700\")\n",
    "\n",
    "    # 6. Confirm SEQN present in FPED\n",
    "    print(\"\\n[6] Check if 93700 exists in FPED:\")\n",
    "    in_fped = 93700 in fped[\"SEQN\"].values\n",
    "    print(\"    Exists in FPED? →\", in_fped)\n",
    "    print(\"    ✓ PASS — FPED contains 93700\" if in_fped else \"    ✗ FAIL — missing from FPED\")\n",
    "\n",
    "    print(\"\\n===============================================\")\n",
    "    print(\"QC complete.\")\n",
    "    print(\"===============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a36ff84d-1ff4-4503-9d29-02e79203f86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "        NHANES MERGE QUALITY CHECK (QC)\n",
      "===============================================\n",
      "\n",
      "[1] Dataset shape:\n",
      "    df_master.shape = (9971, 440)\n",
      "    ✓ PASS — correct number of rows for 2015–2016 DEMO\n",
      "\n",
      "[2] Unique SEQN check:\n",
      "    SEQN unique? → True\n",
      "    ✓ PASS\n",
      "\n",
      "[3] Duplicate merge columns (_x/_y):\n",
      "    Found: []\n",
      "    ✓ PASS — all merge duplicates cleaned\n",
      "\n",
      "[4] FPED variable check:\n",
      "    Number of DR1T_* columns: 37\n",
      "    ✗ FAIL — FPED variables missing\n",
      "\n",
      "[5] DR1DRSTZ for SEQN 93700 (expected = 2.0):\n",
      "    Value: [2.0]\n",
      "    ✓ PASS — correct DR1DRSTZ merge for 93700\n",
      "\n",
      "[6] Check if 93700 exists in FPED:\n",
      "    Exists in FPED? → True\n",
      "    ✓ PASS — FPED contains 93700\n",
      "\n",
      "===============================================\n",
      "QC complete.\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "nhanes_qc(df_master, fped)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
